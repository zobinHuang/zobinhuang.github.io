[{"short":"project_dc_network","name":"Datacenter Network","list":[{"name":"mTCP-accelerated Memcached","tags":["Open Source"],"img_src":"./pic/project_mtcp_memcached/cover.png","link":"https://github.com/zobinHuang/mTCP-memcached","brief":"This project integrated mTCP into libevent and Memcached server. The main difference between origin memcached and this updated one is illustrated in the figure above. Briefly introduced, firstly the mTCP stack was modified to support DPDK 21.11; secondly the libevent library was also updated to contain epoll API from mTCP stack; finally the memcached, the origin network logic in the main thread was removed, where no listening UNIX port will be created, instead #threads of mTCP context will be created on corresponding CPU cores, and theyâ€™re all listen to the same TCP port, load balancing is rely on underlying RSS strategy."},{"name":"OpenRaaS","tags":["Open Source"],"img_src":"./pic/project_openraas/cover.png","link":"https://github.com/zobinHuang/OpenRaaS","brief":"OpenRaaS (i.e. Open Resource-as-a-Service) is a decentralized container-based SaaS platform based on the idea of RaaS, which truely implements the goal of \"deploy applications anywhere with compute or storage capability\". Specifically, OpenRaaS decouples running context of common applications into three parts: runtime environment, runtime file, and render & computation, which would be properly deloyed on different machine on the Internet world respectively, to provide near-user service. The goal of OpenRaaS is to ensure high-quality service for end-users (e.g. low operting latency, short startup delay, etc.) while maximizing the resource utilization for service providers."}]},{"short":"project_mlsys","name":"Machine Learning Systems","list":[{"name":"OneFlow","tags":["Contributor"],"img_src":"","link":"https://github.com/Oneflow-Inc/oneflow","brief":"Developed several operators and primitives for open source framework OneFlow."},{"name":"Deep Graph Library (DGL)","tags":["Contributor"],"img_src":"","link":"https://github.com/dmlc/dgl","brief":"Fixed several bugs inside the dynamic link library of DGL"}]},{"short":"project_embeded","name":"Embeded Systems","list":[{"name":"RL-driven Face Tracking System","tags":["2022 National Embedded Chip and System Design Competition","National First Prize"],"img_src":"./pic/project_socchina/cover.png","link":"./project_socchina/report.pdf","brief":"In the National Embedded Chip and System Design Competition to be held in 2022, I led the team to design a remote conference system using DDPG reinforcement learning model and the YOLOv2 face recognition model. In the remote conference scenario, this device can realize real-time high-precision tracking of the faces of participants. Our devices are developed using HiSilicon Hi3516 and Hi3861 chip-based terminal platforms, using OpenHarmony as the underlying operating system. We ended up winning the National First Prize."},{"name":"Periodic Signal Synchronous Transmission System Based on IEEE 1588","tags":["2019 National Undergraduate Electronic Design Competition","National Second Prize"],"img_src":"./pic/project_internet_based_signal_transmit_system/e_problem.png","link":"./project_internet_based_signal_transmission_system/index.html","brief":"In the National Undergraduate Electronic Design Competition held in the summer of 2019, I led the team to design a signal transmission system based on IEEE 1588 (PTP, Precision Time Stamping Protocol), which realized synchronous periodic signal acquisition and regeneration on distributed network nodes (i.e. In the figure, terminals A and B collect two different periodic signals, and use the physical network to send the collected data to terminal C, which reproduces two periodic signals synchronously). With the precision and stability of the system at the millisecond level, we finally won the National Second Prize."},{"name":"Wearable Intelligent Guidance System for Blind People","tags":["2019 \"Internet+\" College Students Innovation and Entrepreneurship Competition","National Patent"],"img_src":"./pic/project_wearable_intellegent_guide_device/xupeng.png","link":"./project_a_wearable_intelligent_guide_device/index.html","brief":"From October 2018 to October 2019, I participated in the development of a wearable intelligent blind guidance device for assisting blind people in indoor and outdoor travel. In addition to writing the underlying driver software for the system MCU (model: STM32F7 & STM32F1), I am responsible for designing and implementing the high-precision navigation algorithm based on Kalman Filter (Kalman Filter) fusion of GPS and inertial navigation data. This device obtained a national patent in 2019 and has been put into test use in some special education schools in Chengdu."}]}]