<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Exo 2:300,300italic,400,400italic,700,700italic|Caveat:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zobinhuang.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:type" content="website">
<meta property="og:title" content="第一个分类算法：逻辑回归">
<meta property="og:url" content="https://zobinhuang.github.io/sec_learning/Algorithm/ML_3_Logistic_Regression/index.html">
<meta property="og:site_name" content="Zobin">
<meta property="og:description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Algorithm/ML_3_Logistic_Regression/pic/sigmoid.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Algorithm/ML_3_Logistic_Regression/pic/newton.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Algorithm/ML_3_Logistic_Regression/pic/newton_1.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Algorithm/ML_3_Logistic_Regression/pic/xxx.png">
<meta property="article:published_time" content="2022-09-15T08:27:34.702Z">
<meta property="article:modified_time" content="2022-09-15T08:27:34.702Z">
<meta property="article:author" content="Zhuobin Huang">
<meta property="article:tag" content="Zobin">
<meta property="article:tag" content="黄卓彬">
<meta property="article:tag" content="zobinHuang">
<meta property="article:tag" content="网络工程">
<meta property="article:tag" content="Networking Engineering">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png">

<link rel="canonical" href="https://zobinhuang.github.io/sec_learning/Algorithm/ML_3_Logistic_Regression/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>第一个分类算法：逻辑回归 | Zobin
</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Zobin" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zobin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Lovin' Tech with Tea</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about-me-(关于我)">

    <a href="/sec_about/" rel="section"><i class="fa fa-user fa-fw"></i>About Me (关于我)</a>

  </li>
        <li class="menu-item menu-item-library-(知识库)">

    <a href="/sec_learning" rel="section"><i class="fa fa-duotone fa-book fa-fw"></i>Library (知识库)</a>

  </li>
        <li class="menu-item menu-item-music-(独立音乐人)">

    <a href="/sec_music" rel="section"><i class="fa fa-music fa-fw"></i>Music (独立音乐人)</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
  
  

          <div class="content page posts-expand">
            

    
    
    
    <div class="post-block" lang="en">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">第一个分类算法：逻辑回归
</h1>

<div class="post-meta">
  
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Algorithm/">ALGORITHM</a></li>
          <li>ML_3_LOGISTIC_REGRESSION</li>
        
  </ul>

</div>

</header>

      
      
      
      <div class="post-body">
          <head>
<!--导入样式表-->
<link rel="stylesheet" type="text/css" href="style/index.css">

<!--导入网页脚本-->
<script src="script/index.js"></script>

<!--支持伪代码显示-->
<script>
    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3.0.0/es5/tex-chtml.js"
        integrity="sha256-3Fdoa5wQb+JYfEmTpQHx9sc/GuwpfC/0R9EpBki+mf8=" crossorigin>
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js">
</script>

<!--支持网页公式显示-->    
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>

<!--支持矩阵显示-->
<script type="text/javascript">
  run_maths = function() {
    if (document.querySelector('[class*="cmath"]') !== null) {
      if (typeof (mjax_path)=='undefined') { mjax_path='https://cdn.jsdelivr.net/npm/mathjax@2'; }
      if (typeof (mjax_config)=='undefined') { mjax_config='AM_CHTML'; }
      smjax = document.createElement ('script');
      smjax.setAttribute('src',`${mjax_path}/MathJax.js?config=${mjax_config}`);
      smjax.setAttribute('async',true);
      document.getElementsByTagName('head')[0].appendChild(smjax);
    }
  };
  if (document.readyState === 'loading') {  
    window.addEventListener('DOMContentLoaded', run_maths); 
  } else { 
    run_maths(); 
  }
</script>
</head>

<body onload="load_page()">

<div align="center" class="div_indicate_source">
  <h4>⚠ 转载请注明出处：<font color="red"><i>作者：ZobinHuang，更新日期：Apr.5 2022</i></font></h4>
</div>
<div class="div_licence">
  <br>
  <div align="center">
      <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="知识共享许可协议" style="border-width:0; margin-left: 20px; margin-right: 20px;" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a>
  </div>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;本<span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" rel="dct:type">作品</span>由 <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName"><b>ZobinHuang</b></span> 采用 <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><font color="red">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</font></a> 进行许可，在进行使用或分享前请查看权限要求。若发现侵权行为，会采取法律手段维护作者正当合法权益，谢谢配合。
  </p>
</div>
<br>
<div class="div_catalogue">
  <div align="center">
    <h1> 目录 </h1>
    <p>
    <font size="3px">有特定需要的内容直接跳转到相关章节查看即可。</font>
  </div>
  <div class="div_load_catalogue_alert" id="load_catalogue_alert">正在加载目录...</div>
  <div class="div_catalogue_container" id="catalogue_container">
  </div>
</div><br>

<!-- Start your post here -->
<h2 class="title">最大似然分析 Machine Learning 的思路</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在上一篇文章中，我们介绍了基于最大似然来分析 Machine Learning 定义的 Loss Function 的本质的思路，总结来说，这个思路可以抽象为如下四步:

  <div class="border">
  <ol>
    <li>
      首先，我们需要定义出 Hypothesis 的形式;
      <div class="theorm_prove">
      在 Linear Regression 的例子中，我们定义出了 $h_{\Theta}(X^{(i)}) = \hat{Y^{(i)}} = \Theta^{T}X^{(i)}$
      </div>
    </li>
    <li>
      然后，基于把 Hypothesis 的输入特征 $X_{\text{h}}^{(i)}$ 和这份输入特征对应的标签 $Y_{\text{h}}^{(i)}$ 视为随机变量的思路，我们需要定义出这两个随机变量满足的分布，通常表达为条件概率分布 $p(Y_{\text{h}}^{(i)}|X_{\text{h}}^{(i)};\Theta)$，并且我们需要把上面定义出来的 Hypothesis 的形式放入该分布的表达式中;
     <div class="theorm_prove">
      在 Linear Regression 的例子中，我们定义出了 $p(Y_{\text{h}}^{(i)}|X_{\text{h}}^{(i)};\Theta) = \frac{1}{\sqrt{2\pi}\sigma} \cdot \exp(-\frac{(Y_{\text{h}}^{(i)}-\Theta^TX_{\text{h}}^{(i)})^2}{2\sigma^2})$
      </div>
    </li>
    <li>
      基于上面定义出来的分布表达式，通过代入 Training Set 提供的 Samples，我们可以得到似然函数 $\mathcal{L}(\Theta)$;
      <div class="theorm_prove">
      在 Linear Regression 的例子中，我们定义出了 
      $$\mathcal{L}(\Theta) = p(Y_{\text{h}}=Y|X_{\text{h}}=X;\Theta) =\prod_{i=0}^{m-1} \frac{1}{\sqrt{2\pi}\sigma} \cdot \exp(-\frac{(Y^{(i)}-\Theta^TX^{(i)})^2}{2\sigma^2})$$
      </div>
    </li>
    <li>
      通过基于 Gradient Ascent/Desent 等的求解器，以最大似然值/最小损失值为目标，求解出参数值。
    </li>
  </ol>
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;本文我们将讨论我们在 Machine Learning 中见识到的第一个分类算法 —— 逻辑回归，我们下文将采用上面展示的四个步骤对逻辑回归算法的流程进行分析。
</div>

<h2 class="title">学习算法: 逻辑回归 (Logistic Regression)</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;上文讨论的 Linear Regression 问题中，Hypothesis 输出的 $h_{\Theta}(X^{(i)}) = \hat{Y^{(i)}} = \Theta^{T}X^{(i)}$ 预测值是一个连续值。在分类问题中，我们的输出是离散值，这里我们以 <def>二元分类 (Binary Classification)</def> 这种简单的情况进行考虑。

  <h3 class="title">定义 Hypothesis</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于二元分类问题，Training Set 的标签 $Y^{(i)}$ 有两种情况: $\{0,1\}$。我们可以把 Hypothesis 的输出值约束在 $[0,1]$ 区间内，此时我们的分类器可以基于 Hypothesis 的输出更接近 $0$ 还是 $1$ 来实现分类的功能。为了实现对 Hypothesis 的输出值在 $[0,1]$ 区间内的约束，我们可以借助于 <def>sigmoid</def> 函数 (或称为 <def>logistic</def> 函数) 来实现，该函数的表达式如下所示:

  <div class="equation">
  $g(z)=\frac{1}{1+e^{-z}}$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;该函数的特点是可以把输入的 $[-\infty,+\infty]$ 的实数映射到 $[0,1]$ 区间中，其图像如下所示:

  <div class="img" title="sigmoid 函数">
    <img src="./pic/sigmoid.png" width="400px" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;因此，我们可以这样定义二元分类问题的 Hypothesis:

  <div class="equation" label="hypothesis_define">
  $h_{\Theta}(X^{(i)}) = g(\Theta^{T}X^{(i)}) = \frac{1}{1+e^{-\Theta^{T}X^{(i)}}}$
  </div>

  <h3 class="title">定义随机变量 $X^{(i)}_{\text{h}}$ 和 $Y^{(i)}_{\text{h}}$ 的分布</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;现在我们需要确定 $X^{(i)}_{\text{h}}$ 和 $Y^{(i)}_{\text{h}}$ 的分布。注意到 <equation>hypothesis_define</equation> 所定义的 Hypothesis，其可以被解释为随机变量 $X^{(i)}_{\text{h}}$ 取值为 $X^{(i)}$ 时，它被归入类别 $1$ 的概率，因此我们可以得到:

  <div class="equation" label="class_1">
  $p(Y_{\text{h}}^{(i)}=1|X_{\text{h}}^{(i)};\Theta) = h_{\Theta}(X_{\text{h}}^{(i)})$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于归入类别 $0$ 的概率，我们可以用以下式子得到:

  <div class="equation" label="class_0">
  $p(Y_{\text{h}}^{(i)}=0|X_{\text{h}}^{(i)};\Theta) = 1-h_{\Theta}(X_{\text{h}}^{(i)})$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对 <equation>class_1</equation> 和 <equation>class_0</equation> 进行整合，可以得到:

  <div class="equation" label="class_merged">
  $p(Y_{\text{h}}^{(i)}|X_{\text{h}}^{(i)};\Theta) = h_{\Theta}(X_{\text{h}}^{(i)})^{y} \cdot \left(1-h_{\Theta}(X_{\text{h}}^{(i)})\right)^{(1-y)}$
  </div>

  <h3 class="title">基于训练集确定似然函数</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;假设用于训练的所有 $m$ 条 Samples $(X,Y)$ 都是相互独立的，那么基于 <equation>class_merged</equation>，我们可以得到似然函数表达式:

  <div class="equation" label="likelyhood_lr">
  \begin{aligned}
  \mathcal{L}(\Theta) &= p(Y_{\text{h}}=Y|X_{\text{h}}=X;\Theta) \\
  &= \prod_{i=0}^{m-1} p(Y^{(i)}_{\text{h}}=Y^{(i)}|X^{(i)}_{\text{h}}=X^{(i)};\Theta) \\
  &= \prod_{i=0}^{m-1} h_{\Theta}(X^{(i)})^{Y^{(i)}} \cdot \left(1-h_{\Theta}(X^{(i)})\right)^{\left(1-Y^{(i)}\right)}
  \end{aligned}
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;与分析 Linear Regression 问题时一样，我们可以通过分析对数似然函数，将 $\mathcal{L}(\Theta)$ 出现的累乘符号去掉，如下所示:

  <div class="equation" label="log_likelyhood_lr">
  \begin{aligned}
  \mathcal{l}(\Theta) &= \log \mathcal{L}(\Theta)\\
  &= \sum_{i=0}^{m} Y^{(i)} \cdot \log h_{\Theta}(X^{(i)}) + \left(1-Y^{(i)}\right) \cdot \log \left(1-h_{\Theta}(X^{(i)})\right)
  \end{aligned}
  </div>

  <h3 class="title">求解参数</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;此时，我们的目标就是最大化以 <equation>log_likelyhood_lr</equation> 代表的似然值。由于是最大化，因此我们的参数更新采用的是 <def>梯度上升 (Gradient Ascent)</def> 的方式，可以表达如下:

  <div class="equation" label="gradient_ascent">
  $\Theta \leftarrow \Theta + \alpha \cdot \frac{\partial}{\partial \Theta}\mathcal{l}(\Theta)$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;基于 <equation>log_likelyhood_lr</equation> 对 $\mathcal{l}(\Theta)$ 的定义，用 $\mathcal{l}(\Theta)$ 对 $\Theta$ 求导的计算过程如下 (p.s. ① 以单条 Training Sample 为例，因此去掉了 <equation>log_likelyhood_lr</equation> 中的累加符号；② 以单个参数 $\theta_j$ 为例)

  <div class="equation" label="log_likelyhood_lr_derivation">
  \begin{aligned}
  \frac{\partial}{\partial \theta_j}\mathcal{l}(\Theta) &= \frac{\partial}{\partial \theta_j} \left[ Y^{(i)} \cdot \log h_{\Theta}(X^{(i)}) + \left(1-Y^{(i)}\right) \cdot \log \left(1-h_{\Theta}(X^{(i)})\right) \right] \\ \\
  &= \left[ Y^{(i)} \cdot \frac{1}{h_{\Theta}(X^{(i)})} - (1-Y^{(i)}) \frac{1}{1-h_{\Theta}(X^{(i)})} \right] \cdot \frac{\partial}{\partial \theta_j} h_{\Theta}(X^{(i)}) \\ \\
  &= \left[ Y^{(i)} \cdot \frac{1}{g(\Theta^{T}X^{(i)})} - (1-Y^{(i)}) \frac{1}{1-g(\Theta^{T}X^{(i)})} \right] \cdot \frac{\partial}{\partial \theta_j} g(\Theta^{T}X^{(i)}) \\ \\
  &= \left[ Y^{(i)} \cdot \frac{1}{g(\Theta^{T}X^{(i)})} - (1-Y^{(i)}) \frac{1}{1-g(\Theta^{T}X^{(i)})} \right] \cdot g(\Theta^{T}X^{(i)})\left(1-g(\Theta^{T}X^{(i)})\right) \cdot \frac{\partial}{\partial \theta_j} \Theta^TX^{(i)} \\ \\
  &= \left(Y^{(i)}(1-g(\Theta^{T}X^{(i)})) - (1-Y^{(i)})g(\Theta^{T}X^{(i)}) \right) \cdot X^{(i)}_{j} \\ \\
  &= \left(Y^{(i)} - h_{\Theta}(X^{(i)}) \right) \cdot X^{(i)}_{j}
  \end{aligned}
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;因此，结合 <equation>gradient_ascent</equation> 和 <equation>log_likelyhood_lr_derivation</equation>，我们可以得到每个参数的更新式子为:

  <div class="equation" label="per_parameter_update">
  $\theta_j \leftarrow \theta_j + \alpha \cdot \left(Y^{(i)} - h_{\Theta}(X^{(i)}) \right) \cdot X^{(i)}_{j}$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;这个式子实际上和我们上一篇文章基于梯度下降求解 Linear Regression 的参数时的式子是同构的。
</div>

<h2 class="title">学习算法: Perceptron (感知机)</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<def>Perceptron (感知机)</def> 与上面介绍的 Logistic Regression 类似，其区别在于它的 Hypothesis $h(X_{\text{h}};\Theta)=g(\Theta^{T}X_{\text{h}})$ 中的非线性函数 $g(z)$ 的定义为如下形式:

  <div class="equation" label="force">
  $g(z) = 
  \begin{cases}
  1\text{ , if } z \ge 0 \\
  0\text{ , if } z < 0 
  \end{cases}$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;Perceptron 学习算法比较难用概率解释来进行说明，因此也无法使用上面介绍的最大似然概率解释来分析其背后的原理，此处说明只作为了解。
</div>

<h2 class="title">求解器: 牛顿迭代法 (Newton's Method)</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;本节中我们将看到另一种参数求解器设计，Namly <def>牛顿迭代法 (Newton' Method)</def>。给定一个函数 $f(\Theta)$，牛顿迭代法的目标是求到使得 $f(\Theta)=0$ 的 $\Theta$ 取值，在我们的场景中的作用即是求解似然函数 $\mathcal{l}(\Theta)=0$ 时的 $\Theta$ 取值。

  <div class="img" title="牛顿迭代法" label="newton">
    <img src="./pic/newton.png" width="400px" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;我们首先使用示意图来说明其工作模式。如 <imgref>newton</imgref> 所示，假设我们的初始参数取值点为 $\theta_0$，显然我们的目标点是 $\text{target}$。我们首先在 $\theta_0$ 处求解一阶导数，然后基于一阶导数形成的直线，找到其与 x 轴的交点，也即 $\theta_1$，然后重复上述操作。可以看到四次迭代之后找到的 $\theta_3$ 就已经十分接近我们要求解的 $\text{target}$ 点了。

  <div class="img" title="牛顿迭代法单步示意图" label="newton_1">
    <img src="./pic/newton_1.png" width="400px" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;现在让我们来看我们如何在数学上对牛顿迭代法进行表示。如 <imgref>newton_1</imgref> 所示，我们考虑牛顿迭代法中的单步操作。我们把前后两个参数取值之间的距离写作 $\Delta$，则参数的第 $t+1$ 次更新可以写作:

  <div class="equation" label="update">
  $\theta^{(t+1)} \leftarrow \theta^{(t)} - \Delta$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;根据一阶导数与切线斜率的关系，我们可以得到:

  <div class="equation" label="tan">
  $f'(\theta^{(t)}) = \frac{f(\theta^{(t)})}{\Delta}$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;因此可以得到:

  <div class="equation" label="tan">
  $ \Delta = \frac{f(\theta^{(t)})}{f'(\theta^{(t)})}$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;如果我们把 $f(\theta^{(t)})$ 替换为我们场景中的似然函数一阶导数 $\mathcal{l}'(\theta)$，则可以得到:

  <div class="equation" label="tan_1">
  $ \Delta = \frac{\mathcal{l}'(\theta^{(t)})}{\mathcal{l}''(\theta^{(t)})}$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;因此有:

  <div class="equation" label="update">
  $\theta^{(t+1)} \leftarrow \theta^{(t)} - \frac{\mathcal{l}'(\theta^{(t)})}{\mathcal{l}''(\theta^{(t)})}$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;如果考虑向量 $\Theta$ 而不是标量 $\theta$ 的情况，则表达式为：

  <div class="equation" label="update_vector">
  $\Theta^{(t+1)} \leftarrow \Theta^{(t)} + H^{-1} \nabla_{\Theta}\mathcal{l}(\Theta)$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;其中，$\nabla_{\Theta}\mathcal{l}(\Theta)$ 的结果是 $\mathbb{R}^{n+1}$，具体可见 <equation>log_likelyhood_lr_derivation</equation>; 而 $H$ 则是 <def>海森矩阵 (Hessian Matrix)</def>，即 $H_{ij} = \frac{\partial^2\mathcal{l}(\Theta)}{\partial \theta_i \partial \theta_j}$，形式为 $\mathbb{R}^{(n+1)\times(n+1)}$。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;牛顿迭代法的好处是其收敛性能较快，缺点是其在参数维度较大的时候，计算开销会变得很大。
</div>

<div class="div_ref" id="ref_container"></div>

</body>


<!--等式、引用-->
<!-- 
<div class="equation">
</div>

<equation>1</equation>
-->

<!--定理、引用、证明-->
<!-- 
<div class="theorm">
</div>

<theorm>1</theorm>

<div class="theorm_prove">
</div>
-->

<!--引用其它章节-->
<!-- 
<ref></ref> 
-->

<!--引用文献-->
<!-- 
<cite></cite> 
-->

<!--关键词-->
<!-- 
<def></def> 
-->

<!--醒目注意-->
<!-- 
<note></note> 
-->

<!--表格-->
<!--
<table border="1" align="center" bgcolor="#FFFFFF">
  <caption>表格</caption>
  <tr>
    <th>A</th>
    <th>B</th>
    <th>C</th>
  </tr>
  <tr>
    <td>xxx</td>
    <td>xxx</td>
    <td>xxx</td>
  </tr>
</table>
-->

<!--矩阵公式-->
<!--
<div class="cmath" align="center">
  `((1, 0),(1, 0))`
</div><br>
-->

<!--伪代码-->
<!--
<pre id="quicksort" style="display:hidden;">
  % This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
  \begin{algorithm}
  \caption{Quicksort}
  \begin{algorithmic}
  \PROCEDURE{Quicksort}{$A, p, r$}
      % Add Here

      % 空行
      % \STATE \texttt{\\}
  \ENDPROCEDURE
  \end{algorithmic}
  \end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("quicksort"));
</script>
-->
<!--
Latex 伪代码格式见: https://github.com/SaswatPadhi/pseudocode.js
-->

<!--图片-->
<!--
<div align="center">
  <img src="./pic/xxx.png" width=80%>
</div>
-->

<!--正文-->
<!--
<p>
&nbsp;&nbsp;&nbsp;&nbsp;公式：<span>`\overline{A}\overline{B}`</span>
</p>
-->
      </div>
      
      
      
    </div>
    
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Algorithm/">ALGORITHM</a></li>
          <li>ML_3_LOGISTIC_REGRESSION</li>
        
  </ul>

    
    
    


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhuobin Huang"
      src="/images/avatar_2.png">
  <p class="site-author-name" itemprop="name">Zhuobin Huang</p>
  <div class="site-description" itemprop="description">System Engineer</div>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhuobin Huang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
