<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Exo 2:300,300italic,400,400italic,700,700italic|Caveat:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zobinhuang.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":180,"display":"post","padding":10,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:type" content="website">
<meta property="og:title" content="在 Oneflow 中开发算子的基本流程">
<meta property="og:url" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/Oneflow_Operator_Development/index.html">
<meta property="og:site_name" content="Zobin">
<meta property="og:description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/Oneflow_Operator_Development/pic/fused_glu_split.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/Oneflow_Operator_Development/pic/fused_glu.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/Oneflow_Operator_Development/pic/naive_impt_ncu_1.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/Oneflow_Operator_Development/pic/naive_impt_ncu_2.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/Oneflow_Operator_Development/pic/xxx.png">
<meta property="article:published_time" content="2023-02-04T06:06:51.241Z">
<meta property="article:modified_time" content="2023-02-04T06:06:51.241Z">
<meta property="article:author" content="Zhuobin Huang">
<meta property="article:tag" content="Zobin">
<meta property="article:tag" content="黄卓彬">
<meta property="article:tag" content="zobinHuang">
<meta property="article:tag" content="网络工程">
<meta property="article:tag" content="Networking Engineering">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/Oneflow_Operator_Development/pic/fused_glu_split.png">

<link rel="canonical" href="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/Oneflow_Operator_Development/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>在 Oneflow 中开发算子的基本流程 | Zobin
</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Zobin" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zobin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Lovin' Tech with Tea</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about-me">

    <a href="/sec_about/" rel="section"><i class="fa fa-user fa-fw"></i>About Me</a>

  </li>
        <li class="menu-item menu-item-library">

    <a href="/sec_learning/" rel="section"><i class="fa fa-duotone fa-book fa-fw"></i>Library</a>

  </li>
        <li class="menu-item menu-item-production">

    <a href="/sec_music/" rel="section"><i class="fa fa-music fa-fw"></i>Production</a>

  </li>
        <li class="menu-item menu-item-thoughts">

    <a href="/sec_thoughts/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Thoughts</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
  
  

          <div class="content page posts-expand">
            

    
    
    
    <div class="post-block" lang="en">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">在 Oneflow 中开发算子的基本流程
</h1>

<div class="post-meta">
  
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Tech_System_And_Network/">TECH_SYSTEM_AND_NETWORK</a></li>
          <li>ONEFLOW_OPERATOR_DEVELOPMENT</li>
        
  </ul>

</div>

</header>

      
      
      
      <div class="post-body">
          <head>
<!--导入样式表-->
<link rel="stylesheet" type="text/css" href="style/index.css">

<!--导入网页脚本-->
<script src="script/index.js"></script>

<!--支持伪代码显示-->
<script>
    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3.0.0/es5/tex-chtml.js"
        integrity="sha256-3Fdoa5wQb+JYfEmTpQHx9sc/GuwpfC/0R9EpBki+mf8=" crossorigin>
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js">
</script>

<!--支持网页公式显示-->    
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>

<!--支持矩阵显示-->
<script type="text/javascript">
  run_maths = function() {
    if (document.querySelector('[class*="cmath"]') !== null) {
      if (typeof (mjax_path)=='undefined') { mjax_path='https://cdn.jsdelivr.net/npm/mathjax@2'; }
      if (typeof (mjax_config)=='undefined') { mjax_config='AM_CHTML'; }
      smjax = document.createElement ('script');
      smjax.setAttribute('src',`${mjax_path}/MathJax.js?config=${mjax_config}`);
      smjax.setAttribute('async',true);
      document.getElementsByTagName('head')[0].appendChild(smjax);
    }
  };
  if (document.readyState === 'loading') {  
    window.addEventListener('DOMContentLoaded', run_maths); 
  } else { 
    run_maths(); 
  }
</script>
</head>

<body onload="load_page()">

<!-- 导入 mermaid -->
<script src="script/mermaid.min.js"></script>
<script>mermaid.initialize({startOnLoad:true});</script>

<!-- 导入 chart.js -->
<script src="script/chart.min.js"></script>

<!-- 本文的 Metadata -->
<div id="metadata"></div>

<!-- Start your post here -->
<h2 class="title">前言</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;TODO
</div>

<h2 class="title">背景: GLU 及其变种的计算过程</h2>
<div class="div_learning_post">
  <h3 class="title">前向计算过程</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;参考 GLU Variants Improve Transformer <cite>glu_var_paper</cite> 这篇 Paper，GLU 及其变种的计算过程如下所示:

  <div class="equation" label="glu_identity">
  $\text{GLU}_{\text{Identity}}(X,W,V,B,C)=(XW+B)\otimes(XV+C)$
  </div>

  <div class="equation" label="glu_sigmoid">
  $\text{GLU}_{\text{sigmoid}}(X,W,V,B,C)=\sigma(XW+B)\otimes(XV+C)$
  </div>

  <div class="equation" label="glu_relu">
  $\text{GLU}_{\text{relu}}(X,W,V,B,C)=\text{RELU}(XW+B)\otimes(XV+C)$
  </div>

  <div class="equation" label="glu_gelu">
  $\text{GLU}_{\text{gelu}}(X,W,V,B,C)=\text{GELU}(XW+B)\otimes(XV+C)$
  </div>

  <div class="equation" label="glu_silu">
  $\text{GLU}_{\text{silu}}(X,W,V,B,C)=\text{SILU}(XW+B)\otimes(XV+C)$
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;可以发现，上述变种的区别就在于计算式子中的激活函数不同，其余的计算过程基本一致: 给定一个输入张量 $X$，参数张量 $W$ 和 $V$，以及偏移张量 $B$ 和 $C$，首先进行 $(XW+B)$ 和 $(XV+C)$ 的线性运算 (p.s. 下文把前者的结果称为 <code>gate</code>，把后者的结果称为 <code>hidden_state</code>)；完成线性运算后，在 <code>gate</code> 上应用相应的激活函数 (p.s. 得到的结果下文称为 <code>act_gate</code>)；最终将 <code>hidden_state</code> 和 <code>act_gate</code> 上应用 Element-wise 的乘法，得到最终的结果。下面我们就这个计算式，对我们将要设计的算子的输入输出进行分析。

  <div class="img" title="Glu 计算过程图示" label="img_fused_glu_split">
    <img src="./pic/fused_glu_split.png" width="100%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;上面描述的计算过程如 <imgref>img_fused_glu_split</imgref> 所示，用户提供形状为 $\underbrace{[..., m, k]}_{\text{可能不止两维}}$ 的输入张量 $X$，形状为 $[k, n]$ 的参数张量 $W$ 和 $V$ (p.s. 通常被转置为 $[n, k]$ 提供)，以及形状为 $[n]$ 的偏移张量 $B$ 和 $C$，GLU 输出一个形状为 $[..., m, n]$ 的张量。

  <div class="img" title="Glu 计算过程图示 (合并形式)" label="img_fused_glu">
    <img src="./pic/fused_glu.png" width="100%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;同时，我们也可以允许用户给定一个合并的参数张量和一个偏移张量，如 <imgref>img_fused_glu</imgref> 所示，用户仅提供形状为 $[m, k]$ 的输入张量 $X$，$[k, 2n]$ 的参数张量 $W$ 以及 $[2n]$ 的偏移张量 $B$，通过在算子内部进行 Chunk 操作，我们可以实现和上面一样的计算过程。这样一来，我们的算子就需要对输入的张量进行判断: 如果同时提供了 $X$, $W$, $V$, $B$ 和 $C$ 五个输入张量，则运行 <imgref>img_fused_glu_split</imgref> 所示的计算过程; 如果只提供了 $X$, $W$, 和 $B$ 三个张量，则运行 <imgref>img_fused_glu</imgref> 所示的计算过程。在下文中，我们把前者称为 <note>Merged</note> 实现，后者称为 <note>Splited</note> 实现。

</div>

<h2 class="title">Motivation: 为什么需要为 GLU 构造 Fused 实现?</h2>
<div class="div_learning_post">
  <h3 class="title">性能之殇</h3>
  <h4 class="paragraph">Naive 实现</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;采用最 Naive 的方法，我们可以在 Oneflow 中通过构造继承自 <code>nn.Module</code> 的类来实现 GLU 的计算过程，源码如下:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> oneflow <span class="keyword">as</span> flow</span><br><span class="line"><span class="keyword">import</span> oneflow.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Glu</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">      self,</span></span></span><br><span class="line"><span class="function"><span class="params">      x: flow.Tensor,             <span class="comment"># 输入张量 x</span></span></span></span><br><span class="line"><span class="function"><span class="params">      w: flow.Tensor,             <span class="comment"># 参数张量 w</span></span></span></span><br><span class="line"><span class="function"><span class="params">      b: flow.Tensor,             <span class="comment"># 偏移张量 b</span></span></span></span><br><span class="line"><span class="function"><span class="params">      v: flow.Tensor = <span class="literal">None</span>,      <span class="comment"># 参数张量 v (optional)</span></span></span></span><br><span class="line"><span class="function"><span class="params">      c: flow.Tensor = <span class="literal">None</span>,      <span class="comment"># 偏移张量 c (optional)</span></span></span></span><br><span class="line"><span class="function"><span class="params">      split_mode: <span class="built_in">bool</span> = <span class="literal">False</span>,   <span class="comment"># 指示是否是分离参数张量的输入</span></span></span></span><br><span class="line"><span class="function"><span class="params">      activation: <span class="built_in">str</span> = <span class="string">&quot;none&quot;</span>,   <span class="comment"># 指示激活函数类型</span></span></span></span><br><span class="line"><span class="function"><span class="params">  </span>) -&gt; flow.Tensor:</span></span><br><span class="line">      <span class="comment"># matmul</span></span><br><span class="line">      matmul_wx = flow._C.matmul(<span class="built_in">input</span>=x, other=w, transpose_a=<span class="literal">False</span>, transpose_b=<span class="literal">True</span>)</span><br><span class="line">      <span class="keyword">if</span> split_mode:</span><br><span class="line">          matmul_vx = flow._C.matmul(<span class="built_in">input</span>=x, other=v, transpose_a=<span class="literal">False</span>, transpose_b=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># add bias</span></span><br><span class="line">      matmul_wx_b = flow._C.add(<span class="built_in">input</span>=matmul_wx, other=b)</span><br><span class="line">      <span class="keyword">if</span> split_mode:</span><br><span class="line">          matmul_vx_c = flow._C.add(<span class="built_in">input</span>=matmul_vx, other=c)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># chunk</span></span><br><span class="line">      <span class="keyword">if</span> split_mode:</span><br><span class="line">          hidden_state = matmul_wx_b</span><br><span class="line">          gate = matmul_vx_c</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          hidden_state, gate = matmul_wx_b.chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># activation and element-wise product</span></span><br><span class="line">      <span class="keyword">if</span> activation == <span class="string">&quot;none&quot;</span>:</span><br><span class="line">          <span class="keyword">return</span> hidden_state * gate</span><br><span class="line">      <span class="keyword">elif</span> activation == <span class="string">&quot;sigmoid&quot;</span>:</span><br><span class="line">          <span class="keyword">return</span> hidden_state * flow.sigmoid(gate)</span><br><span class="line">      <span class="keyword">elif</span> activation == <span class="string">&quot;relu&quot;</span>:</span><br><span class="line">          <span class="keyword">return</span> hidden_state * flow.relu(gate)</span><br><span class="line">      <span class="keyword">elif</span> activation == <span class="string">&quot;gelu&quot;</span>:</span><br><span class="line">          <span class="keyword">return</span> hidden_state * flow.gelu(gate)</span><br><span class="line">      <span class="keyword">elif</span> activation == <span class="string">&quot;fast_gelu&quot;</span>:</span><br><span class="line">          <span class="keyword">return</span> hidden_state * flow._C.fast_gelu(gate)</span><br><span class="line">      <span class="keyword">elif</span> activation == <span class="string">&quot;silu&quot;</span>:</span><br><span class="line">          <span class="keyword">return</span> hidden_state * flow.silu(gate)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;我们就 Merged 实现分析一下上述程序运行一次前向传播所需要调用的底层 Kernels:

  <div class="table" title="Python 脚本中调用的算子和底层调用的 Kernels 的对应关系">
    <table>
      <tr>
        <th align="center" width="30%">算子</th>
        <th align="center">底层调用的 Kernels</th>
      </tr>
      <tr>
        <td align="center">Matmul</td>
        <td>Line 21 调用的 <code>flow._C.matmul</code> 将最终调用 Primitive <code>Matmul</code> 完成运算 <cite>ofsrc_matmul_kernels_cpp</cite>，而后者则将调用 cuBLAS 的 API <code>cublasGemmEx</code> <cite>nvdoc_cublas_cublasgemmex</cite> 或 <code>cublasGemmStridedBatchedEx</code> <cite>nvdoc_cublas_cublasgemmstridedbatchedex</cite> 完成运算 <cite>ofsrc_broadcast_matmul_cpp</cite></td>
      </tr>
      <tr>
        <td align="center">Add</td>
        <td>Line 26 调用的 <code>flow._C.add</code> 将最终调用 Primitive <code>Add</code> 完成运算 <cite>ofsrc_add_n_kernel_cpp</cite>，而后者则实现了相应的 CUDA Kernel <code>AddGpu</code> <cite>ofsrc_add_cu</cite> 完成运算</td>
      </tr>
      <tr>
        <td align="center">Chunk</td>
        <td></td>
      </tr>
      <tr>
        <td align="center">Activation</td>
        <td></td>
      </tr>
      <tr>
        <td align="center">Element-wise Multiplication</td>
        <td></td>
      </tr>
    </table>
  </div>

  <h4 class="paragraph">Naive 实现的性能测试</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于上述实现，下面我们在不同的激活函数设置下，尝试向这段计算过程中打入不同规模的张量进行计算，并且获取计算过程的时延情况。完整的测试脚本如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> unittest</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> oneflow <span class="keyword">as</span> flow</span><br><span class="line"><span class="keyword">import</span> oneflow.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> oneflow.unittest</span><br><span class="line"><span class="keyword">from</span> oneflow.test_utils.test_util <span class="keyword">import</span> GenArgList</span><br><span class="line"></span><br><span class="line">test_direction = <span class="string">&quot;forward&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Glu</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">        self,</span></span></span><br><span class="line"><span class="function"><span class="params">        x: flow.Tensor,</span></span></span><br><span class="line"><span class="function"><span class="params">        w: flow.Tensor,</span></span></span><br><span class="line"><span class="function"><span class="params">        b: flow.Tensor,</span></span></span><br><span class="line"><span class="function"><span class="params">        v: flow.Tensor = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        c: flow.Tensor = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        split_mode: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        activation: <span class="built_in">str</span> = <span class="string">&quot;none&quot;</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    </span>) -&gt; flow.Tensor:</span></span><br><span class="line">        <span class="comment"># matmul</span></span><br><span class="line">        matmul_wx = flow._C.matmul(</span><br><span class="line">            <span class="built_in">input</span>=x, other=w, transpose_a=<span class="literal">False</span>, transpose_b=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> split_mode:</span><br><span class="line">            matmul_vx = flow._C.matmul(</span><br><span class="line">                <span class="built_in">input</span>=x, other=v, transpose_a=<span class="literal">False</span>, transpose_b=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add bias</span></span><br><span class="line">        matmul_wx_b = flow._C.add(<span class="built_in">input</span>=matmul_wx, other=b)</span><br><span class="line">        <span class="keyword">if</span> split_mode:</span><br><span class="line">            matmul_vx_c = flow._C.add(<span class="built_in">input</span>=matmul_vx, other=c)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># chunk</span></span><br><span class="line">        <span class="keyword">if</span> split_mode:</span><br><span class="line">            hidden_state = matmul_wx_b</span><br><span class="line">            gate = matmul_vx_c</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            hidden_state, gate = matmul_wx_b.chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># activation and element-wise product</span></span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">&quot;none&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> hidden_state * gate</span><br><span class="line">        <span class="keyword">elif</span> activation == <span class="string">&quot;sigmoid&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> hidden_state * flow.sigmoid(gate)</span><br><span class="line">        <span class="keyword">elif</span> activation == <span class="string">&quot;relu&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> hidden_state * flow.relu(gate)</span><br><span class="line">        <span class="keyword">elif</span> activation == <span class="string">&quot;gelu&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> hidden_state * flow.gelu(gate)</span><br><span class="line">        <span class="keyword">elif</span> activation == <span class="string">&quot;fast_gelu&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> hidden_state * flow._C.fast_gelu(gate)</span><br><span class="line">        <span class="keyword">elif</span> activation == <span class="string">&quot;silu&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> hidden_state * flow.silu(gate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensor_builder</span>(<span class="params">params: <span class="built_in">dict</span>, dtype=flow.float32, is_split_mode=<span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="comment"># config test data</span></span><br><span class="line">    m = params[<span class="string">&quot;m&quot;</span>]</span><br><span class="line">    n = params[<span class="string">&quot;n&quot;</span>]</span><br><span class="line">    k = params[<span class="string">&quot;k&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># generate random input</span></span><br><span class="line">    x = np.random.randn(<span class="number">2</span>, m, k) / <span class="number">100</span></span><br><span class="line">    y_nor = np.random.randn(<span class="number">2</span>, m, n)</span><br><span class="line">    <span class="keyword">if</span> is_split_mode:</span><br><span class="line">        w = np.random.randn(n, k) / <span class="number">100</span>  <span class="comment"># transpose</span></span><br><span class="line">        b = np.random.randn(n) / <span class="number">100</span></span><br><span class="line">        v = np.random.randn(n, k) / <span class="number">100</span>  <span class="comment"># transpose</span></span><br><span class="line">        c = np.random.randn(n) / <span class="number">100</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        w = np.random.randn(n * <span class="number">2</span>, k) / <span class="number">100</span>  <span class="comment"># transpose</span></span><br><span class="line">        b = np.random.randn(n * <span class="number">2</span>) / <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># transfer to gpu memory</span></span><br><span class="line">    tensor_x = flow.FloatTensor(x).to(dtype=dtype, device=<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    tensor_y_nor = flow.FloatTensor(y_nor).to(dtype=dtype, device=<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    tensor_w = flow.FloatTensor(w).to(dtype=dtype, device=<span class="string">&quot;cuda&quot;</span>).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">    tensor_b = flow.FloatTensor(b).to(dtype=dtype, device=<span class="string">&quot;cuda&quot;</span>).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> is_split_mode:</span><br><span class="line">        tensor_v = (</span><br><span class="line">            flow.FloatTensor(v).to(dtype=dtype, device=<span class="string">&quot;cuda&quot;</span>).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        tensor_c = (</span><br><span class="line">            flow.FloatTensor(c).to(dtype=dtype, device=<span class="string">&quot;cuda&quot;</span>).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> is_split_mode:</span><br><span class="line">        <span class="keyword">return</span> tensor_x, tensor_w, tensor_b, tensor_v, tensor_c, tensor_y_nor</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> tensor_x, tensor_w, tensor_b, tensor_y_nor</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">profile_naive_glu</span>(<span class="params">test_case, params: <span class="built_in">dict</span>, dtype=flow.float32</span>):</span></span><br><span class="line">    print(<span class="string">f&quot;========== Start Testing ==========&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;impt: naive&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;direction: <span class="subst">&#123;test_direction&#125;</span>&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;weight tensor: merged&quot;</span>)</span><br><span class="line">    print(<span class="string">f&#x27;tensor shape: m=<span class="subst">&#123;params[<span class="string">&quot;m&quot;</span>]&#125;</span>, n=<span class="subst">&#123;params[<span class="string">&quot;n&quot;</span>]&#125;</span>, k=<span class="subst">&#123;params[<span class="string">&quot;k&quot;</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">    print(<span class="string">f&#x27;activation: <span class="subst">&#123;params[<span class="string">&quot;act&quot;</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">    print(<span class="string">f&quot;dtype: <span class="subst">&#123;dtype&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    flow_module = Glu()</span><br><span class="line">    x, w, b, y_nor = tensor_builder(params=params, dtype=dtype, is_split_mode=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    <span class="keyword">if</span> test_direction == <span class="string">&quot;forward&quot;</span>:</span><br><span class="line">        y = flow_module.forward(x=x, w=w, b=b, split_mode=<span class="literal">False</span>, activation=params[<span class="string">&quot;act&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    <span class="keyword">if</span> test_direction == <span class="string">&quot;backward&quot;</span>:</span><br><span class="line">        y.<span class="built_in">sum</span>().backward()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">f&quot;============== PASSED =============&quot;</span>)</span><br><span class="line">    print(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">profile_fused_glu</span>(<span class="params">test_case, params: <span class="built_in">dict</span>, dtype=flow.float32</span>):</span></span><br><span class="line">    print(<span class="string">f&quot;========== Start Testing ==========&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;impt: fused&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;direction: <span class="subst">&#123;test_direction&#125;</span>&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;weight tensor: merged&quot;</span>)</span><br><span class="line">    print(<span class="string">f&#x27;tensor shape: m=<span class="subst">&#123;params[<span class="string">&quot;m&quot;</span>]&#125;</span>, n=<span class="subst">&#123;params[<span class="string">&quot;n&quot;</span>]&#125;</span>, k=<span class="subst">&#123;params[<span class="string">&quot;k&quot;</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">    print(<span class="string">f&#x27;activation: <span class="subst">&#123;params[<span class="string">&quot;act&quot;</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">    print(<span class="string">f&quot;dtype: <span class="subst">&#123;dtype&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    x, w, b, y_nor = tensor_builder(params=params, dtype=dtype, is_split_mode=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    <span class="keyword">if</span> test_direction == <span class="string">&quot;forward&quot;</span>:</span><br><span class="line">        fused_y = flow._C.fused_glu(x=x, w=w, b=b, v=<span class="literal">None</span>, c=<span class="literal">None</span>, activation=params[<span class="string">&quot;act&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    <span class="keyword">if</span> test_direction == <span class="string">&quot;backward&quot;</span>:</span><br><span class="line">        fused_y.<span class="built_in">sum</span>().backward()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">f&quot;============== PASSED =============&quot;</span>)</span><br><span class="line">    print(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@flow.unittest.skip_unless_1n1d()</span></span><br><span class="line"><span class="meta">@unittest.skipIf(<span class="params">os.getenv(<span class="params"><span class="string">&quot;ONEFLOW_TEST_CPU_ONLY&quot;</span></span>), <span class="string">&quot;only test gpu cases&quot;</span></span>)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestFusedGlu</span>(<span class="params">flow.unittest.TestCase</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_gather</span>(<span class="params">test_case</span>):</span></span><br><span class="line">        arg_dict = OrderedDict()</span><br><span class="line">        <span class="comment"># set up test functions</span></span><br><span class="line">        arg_dict[<span class="string">&quot;test_fun&quot;</span>] = [</span><br><span class="line">            profile_naive_glu,</span><br><span class="line">            profile_fused_glu,</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># set up env valuable if necessary</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> test_dualgemm_impt:</span><br><span class="line">            os.environ[<span class="string">&quot;ONEFLOW_KERNEL_GLU_ENABLE_DUAL_GEMM_IMPL&quot;</span>] = <span class="string">&quot;false&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            os.environ[<span class="string">&quot;ONEFLOW_KERNEL_GLU_ENABLE_DUAL_GEMM_IMPL&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># set up profiling functions</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> test_dualgemm_impt:</span><br><span class="line">            arg_dict[<span class="string">&quot;params&quot;</span>] = [</span><br><span class="line">                <span class="comment"># m=256, k=1280, n=5120</span></span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">256</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;none&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">256</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;sigmoid&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">256</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;relu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">256</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;gelu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">256</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;fast_gelu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">256</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;silu&quot;</span>&#125;,</span><br><span class="line">                <span class="comment"># m=1024, k=640, n=2560</span></span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">1024</span>, <span class="string">&quot;k&quot;</span>: <span class="number">640</span>, <span class="string">&quot;n&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;none&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">1024</span>, <span class="string">&quot;k&quot;</span>: <span class="number">640</span>, <span class="string">&quot;n&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;sigmoid&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">1024</span>, <span class="string">&quot;k&quot;</span>: <span class="number">640</span>, <span class="string">&quot;n&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;relu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">1024</span>, <span class="string">&quot;k&quot;</span>: <span class="number">640</span>, <span class="string">&quot;n&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;gelu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">1024</span>, <span class="string">&quot;k&quot;</span>: <span class="number">640</span>, <span class="string">&quot;n&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;fast_gelu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">1024</span>, <span class="string">&quot;k&quot;</span>: <span class="number">640</span>, <span class="string">&quot;n&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;silu&quot;</span>&#125;,</span><br><span class="line">                <span class="comment"># m=4096, k=320, n=1280</span></span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">4096</span>, <span class="string">&quot;k&quot;</span>: <span class="number">320</span>, <span class="string">&quot;n&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;none&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">4096</span>, <span class="string">&quot;k&quot;</span>: <span class="number">320</span>, <span class="string">&quot;n&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;sigmoid&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">4096</span>, <span class="string">&quot;k&quot;</span>: <span class="number">320</span>, <span class="string">&quot;n&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;relu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">4096</span>, <span class="string">&quot;k&quot;</span>: <span class="number">320</span>, <span class="string">&quot;n&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;gelu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">4096</span>, <span class="string">&quot;k&quot;</span>: <span class="number">320</span>, <span class="string">&quot;n&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;fast_gelu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">4096</span>, <span class="string">&quot;k&quot;</span>: <span class="number">320</span>, <span class="string">&quot;n&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;silu&quot;</span>&#125;,</span><br><span class="line">                <span class="comment"># m=2560, k=12800, n=51200</span></span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;none&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;sigmoid&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;relu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;gelu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;fast_gelu&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;silu&quot;</span>&#125;,</span><br><span class="line">            ]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            arg_dict[<span class="string">&quot;params&quot;</span>] = [</span><br><span class="line">                <span class="comment"># m=256, k=1280, n=5120</span></span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">256</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;fast_gelu&quot;</span>&#125;,</span><br><span class="line">                <span class="comment"># m=1024, k=640, n=2560</span></span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">1024</span>, <span class="string">&quot;k&quot;</span>: <span class="number">640</span>, <span class="string">&quot;n&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;fast_gelu&quot;</span>&#125;,</span><br><span class="line">                <span class="comment"># m=4096, k=320, n=1280</span></span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">4096</span>, <span class="string">&quot;k&quot;</span>: <span class="number">320</span>, <span class="string">&quot;n&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;fast_gelu&quot;</span>&#125;,</span><br><span class="line">                <span class="comment"># m=2560, k=12800, n=51200</span></span><br><span class="line">                &#123;<span class="string">&quot;m&quot;</span>: <span class="number">2560</span>, <span class="string">&quot;k&quot;</span>: <span class="number">1280</span>, <span class="string">&quot;n&quot;</span>: <span class="number">5120</span>, <span class="string">&quot;act&quot;</span>: <span class="string">&quot;fast_gelu&quot;</span>&#125;,</span><br><span class="line">            ]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> test_dualgemm_impt:</span><br><span class="line">            arg_dict[<span class="string">&quot;dtype&quot;</span>] = [flow.float16, flow.float32]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            arg_dict[<span class="string">&quot;dtype&quot;</span>] = [flow.float16]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> arg <span class="keyword">in</span> GenArgList(arg_dict):</span><br><span class="line">            arg[<span class="number">0</span>](test_case, *arg[<span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    unittest.main()</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;以 Sigmoid 为激活函数为例，当数据类型为 Half (2 Bytes) 和 Float (4 Bytes) 时，在不同张量形状输入下，将上面的测试脚本按照所执行的 Kernels 进行性能分解，如 <chartref>naive_impt_performance_sigmoid_half</chartref> 和 <chartref>naive_impt_performance_sigmoid_float</chartref> 所示:

  <div class="chartjs" label="naive_impt_performance_sigmoid_half"></div>
  <div class="chartjs" label="naive_impt_performance_sigmoid_float"></div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;另外，当设置激活函数为其它形式时，测试结果收录在如下附录中:

  <div class="comblock" title="其它激活函数下的测试结果">
  <h4 class="paragraph">激活函数 - Identity</h4>
  <div class="chartjs" label="naive_impt_performance_identity_half"></div>
  <div class="chartjs" label="naive_impt_performance_identity_float"></div>

  <h4 class="paragraph">激活函数 - Relu</h4>
  <div class="chartjs" label="naive_impt_performance_relu_half"></div>
  <div class="chartjs" label="naive_impt_performance_relu_float"></div>

  <h4 class="paragraph">激活函数 - Gelu</h4>
  <div class="chartjs" label="naive_impt_performance_gelu_half"></div>
  <div class="chartjs" label="naive_impt_performance_gelu_float"></div>

  <h4 class="paragraph">激活函数 - Fast Gelu</h4>
  <div class="chartjs" label="naive_impt_performance_fast_gelu_half"></div>
  <div class="chartjs" label="naive_impt_performance_fast_gelu_float"></div>

  <h4 class="paragraph">激活函数 - Silu</h4>
  <div class="chartjs" label="naive_impt_performance_silu_half"></div>
  <div class="chartjs" label="naive_impt_performance_silu_float"></div>
  </div>

  <h4 class="paragraph">GLU 计算过程的 Kernel 理论运行时间</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;TODO: 粗略地对这个计算过程的理论最优执行时间进行估算

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;TODO: 计算各个张量形状下，开发 Fused Kernel 的收益比

  <div class="comblock" title="怎么进行 Naive 实现的性能测试?">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;由于 Oneflow 的执行是异步的，也就是说 Python 脚本构建出的逻辑计算图的各个 Op 实际上在 Oneflow 的 Runtime 中的执行是异步执行的，因此我们并不能直接在 Python 脚本中对 Duration 进行测试，上述的结果是首先使用 <code>ncu</code> 工具对这段计算过程中调用的各个 Kernels 的 Duration 进行记录，然后将这些 Kernels 的执行时间进行相加得到的。下面我们简单阐述一下这个过程:

  <div class="img" label="img_forward_identity_ncu" title="Nsight Compute 中观察到的 ① 激活函数为 Identity; ② 数据类型为 half/float; ③ 张量形状为 m=256, n=1280, k=5120; 时调用的 Kernels">
    <img src="./pic/naive_impt_ncu_1.png" width="100%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<note>结合上面给出的测试脚本</note>，我们可以尝试将测试过程对应上在 Nsight Compute 中的相应记录结果。这里以前向传播的测试为例进行说明，如 <imgref>img_forward_identity_ncu</imgref> 所示，当我们设置 ① 激活函数为 Identity; ② 数据类型为 half/float; ③ 张量形状为 m=256, n=1280, k=5120 时，我们可以在图中的选中部分观察到对应调用的 Kernels。如果读者对 Oneflow 中相关算子的具体实现不是很熟悉，这里识别的技巧是:

  <ul>
    <li>Kernel 0~3 用于实际上是调用了 <code>CastFunctor</code>，其工作是将 <code>half</code> 类型的张量转换为 <code>float</code> 类型的张量，因此可以判断出这是针对 <code>half</code> 数据类型计算的开端;</li>
    <li>Kernel 4~8 和 Kernel 9~13 实际上拥有类似的 Pattern，因此可以粗略判断出这两部分分别是 <code>half</code> 和 <code>float</code> 的计算过程;</li>
  </ul>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;而实际上，这些 Kernels 的功能分析如下:

  <ul>
    <li><code></code>: </li>
  </ul>

  <div class="img" label="img_forward_sigmoid_ncu" title="Nsight Compute 中观察到的 ① 激活函数为 Sigmoid; ② 数据类型为 half/float; ③ 张量形状为 m=256, n=1280, k=5120; 时调用的 Kernels">
    <img src="./pic/naive_impt_ncu_2.png" width="100%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;同理，我们可以紧接着观察当我们设置 ① 激活函数为 Sigmoid; ② 数据类型为 half/float; ③ 张量形状为 m=256, n=1280, k=5120 时计算过程调用的 Kernels。我们可以发现大部分流程与上面激活函数为 Identity 时基本一致，不同的是 Kernel 21 和 27，它们实际上调用的是 Sigmoid 激活函数对应的 <code>UnaryFunctor</code>，我们在上面没有观察到对 <code>UnaryFunctor</code> 的调用是因为 Identity 实际上什么也没算，因此也无需调用任何 <code>UnaryFunctor</code> 来进行计算。
  </div>

  <h3 class="title">算子设计目标</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<chartref>naive_impt_performance</chartref>
</div>



<h2 class="title">定义 Operator</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;
</div>


<div class="div_ref" id="ref_container"></div>

</body>

<!-- Comment -->
<!-- <div class="comblock" title="xxx"> -->

<!-- Chart Support -->
<!-- Check https://www.runoob.com/chartjs/chartjs-tutorial.html -->
<!-- <div class="chartjs" label="naive_impt_performance"></div> -->


<!-- Note Support -->
<!-- Check https://theme-next.js.org/docs/tag-plugins/note.html -->

<!-- 圆圈数字 -->
<!--
⓪ ① ② ③ ④ ⑤ ⑥ ⑦ ⑧ ⑨ ⑩ ⑪ ⑫ ⑬ ⑭ ⑮ ⑯ ⑰ ⑱ ⑲ ⑳ ㉑ ㉒ ㉓ ㉔ ㉕ ㉖ ㉗ ㉘ ㉙ ㉚ ㉛ ㉜ ㉝ ㉞ ㉟ ㊱ ㊲ ㊳ ㊴ ㊵ ㊶ ㊷ ㊸ ㊹ ㊺ ㊻ ㊼ ㊽ ㊾ ㊿
-->

<!-- Flow Chart -->
<!--
Format see: https://mermaid-js.github.io/mermaid/#/flowchart
-->
<!-- <flowchart class="mermaid">
 Mermaid Flow Chart Code
</flowchart> -->

<!-- Sign Block -->
<!--
<noteblock>
A NOTE
</noteblock>

<queblock>
A QUESTION
</queblock>
-->

<!--图片、引用-->
<!-- 
<div class="img" title="img title" label="img_label" source="url">
  <img src="" height="" />
</div>

<imaging>img_label</imaging>
-->

<!--等式、引用-->
<!-- 
<div class="equation" label="equation_label">
</div>

<equation>equation_label</equation>
-->

<!--定理、引用、证明-->
<!-- 
<div class="theorm" label="theorm_label">
</div>

<theorm>theorm_label</theorm>

<div class="theorm_prove">
</div>
-->

<!--引用其它章节-->
<!-- 
<ref></ref> 
-->

<!--引用文献-->
<!-- 
<cite></cite> 
-->

<!--关键词-->
<!-- 
<def></def> 
-->

<!--醒目注意-->
<!-- 
<note></note> 
-->

<!--段落-->
<!--
<h3 class="paragraph">Paragraph Name</h3>
-->

<!--表格-->
<!--
<div class="table" title="Table Title" label="table_label">
  <table border="1" align="center" bgcolor="#FFFFFF">
    <tr>
      <th>A</th>
      <th>B</th>
      <th>C</th>
    </tr>
    <tr>
      <td>xxx</td>
      <td>xxx</td>
      <td>xxx</td>
    </tr>
  </table>
</div>
-->

<!--矩阵公式-->
<!--
<div class="cmath" align="center">
  `((1, 0),(1, 0))`
</div><br>
-->

<!--伪代码-->
<!--
<pre id="quicksort" style="display:hidden;">
  % This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
  \begin{algorithm}
  \caption{Quicksort}
  \begin{algorithmic}
  \PROCEDURE{Quicksort}{$A, p, r$}
      % Add Here

      % 空行
      % \STATE \texttt{\\}
  \ENDPROCEDURE
  \end{algorithmic}
  \end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("quicksort"));
</script>
-->
<!--
Latex 伪代码格式见: https://github.com/SaswatPadhi/pseudocode.js
-->

<!--图片-->
<!--
<div align="center">
  <img src="./pic/xxx.png" width=80%>
</div>
-->

<!--正文-->
<!--
<p>
&nbsp;&nbsp;&nbsp;&nbsp;公式：<span>`\overline{A}\overline{B}`</span>
</p>
-->
      </div>
      
      
      
    </div>
    
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Tech_System_And_Network/">TECH_SYSTEM_AND_NETWORK</a></li>
          <li>ONEFLOW_OPERATOR_DEVELOPMENT</li>
        
  </ul>

    
    
    


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhuobin Huang"
      src="/images/avatar_2.png">
  <p class="site-author-name" itemprop="name">Zhuobin Huang</p>
  <div class="site-description" itemprop="description">System Engineer</div>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zobinHuang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zobinHuang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zobin1999@gmail.com" title="E-Mail → mailto:zobin1999@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhuobin Huang</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
