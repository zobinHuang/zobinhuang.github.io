<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Exo 2:300,300italic,400,400italic,700,700italic|Caveat:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zobinhuang.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":180,"display":"post","padding":10,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:type" content="website">
<meta property="og:title" content="PyTorch 数据加载源码分析">
<meta property="og:url" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/index.html">
<meta property="og:site_name" content="Zobin">
<meta property="og:description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/workflow.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/cooperate.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/map_style.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/iter_style.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/dataloader_wf.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/dataloader_wf_1.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/collate_single.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/collate.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/single_process.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/mp_fetching_logic.png">
<meta property="og:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/xxx.png">
<meta property="article:published_time" content="2022-10-04T15:54:08.035Z">
<meta property="article:modified_time" content="2022-10-04T15:54:08.035Z">
<meta property="article:author" content="Zhuobin Huang">
<meta property="article:tag" content="Zobin">
<meta property="article:tag" content="黄卓彬">
<meta property="article:tag" content="zobinHuang">
<meta property="article:tag" content="网络工程">
<meta property="article:tag" content="Networking Engineering">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/pic/workflow.png">

<link rel="canonical" href="https://zobinhuang.github.io/sec_learning/Tech_System_And_Network/PyTorch_Dataloader/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>PyTorch 数据加载源码分析 | Zobin
</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Zobin" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zobin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Lovin' Tech with Tea</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about-me-(关于我)">

    <a href="/sec_about/" rel="section"><i class="fa fa-user fa-fw"></i>About Me (关于我)</a>

  </li>
        <li class="menu-item menu-item-library-(知识库)">

    <a href="/sec_learning" rel="section"><i class="fa fa-duotone fa-book fa-fw"></i>Library (知识库)</a>

  </li>
        <li class="menu-item menu-item-music-(独立音乐人)">

    <a href="/sec_music" rel="section"><i class="fa fa-music fa-fw"></i>Music (独立音乐人)</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
  
  

          <div class="content page posts-expand">
            

    
    
    
    <div class="post-block" lang="en">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">PyTorch 数据加载源码分析
</h1>

<div class="post-meta">
  
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Tech_System_And_Network/">TECH_SYSTEM_AND_NETWORK</a></li>
          <li>PYTORCH_DATALOADER</li>
        
  </ul>

</div>

</header>

      
      
      
      <div class="post-body">
          <head>
<!--导入样式表-->
<link rel="stylesheet" type="text/css" href="style/index.css">

<!--导入网页脚本-->
<script src="script/index.js"></script>

<!--支持伪代码显示-->
<script>
    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3.0.0/es5/tex-chtml.js"
        integrity="sha256-3Fdoa5wQb+JYfEmTpQHx9sc/GuwpfC/0R9EpBki+mf8=" crossorigin>
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js">
</script>

<!--支持网页公式显示-->    
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>

<!--支持矩阵显示-->
<script type="text/javascript">
  run_maths = function() {
    if (document.querySelector('[class*="cmath"]') !== null) {
      if (typeof (mjax_path)=='undefined') { mjax_path='https://cdn.jsdelivr.net/npm/mathjax@2'; }
      if (typeof (mjax_config)=='undefined') { mjax_config='AM_CHTML'; }
      smjax = document.createElement ('script');
      smjax.setAttribute('src',`${mjax_path}/MathJax.js?config=${mjax_config}`);
      smjax.setAttribute('async',true);
      document.getElementsByTagName('head')[0].appendChild(smjax);
    }
  };
  if (document.readyState === 'loading') {  
    window.addEventListener('DOMContentLoaded', run_maths); 
  } else { 
    run_maths(); 
  }
</script>
</head>

<body onload="load_page()">

<!-- 导入 mermaid -->
<script src="script/mermaid.min.js"></script>
<script>mermaid.initialize({startOnLoad:true});</script>

<!-- 本文的 Metadata -->
<div id="metadata"></div>

<!-- Start your post here -->
<h2 class="title">基本概念</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在本文中，我们将对 <code>torch.utils.data</code> 模块中的 <b>Dataset</b>，<b>BatchSampler</b> 和 <b>DataLoader</b> 三个用于 PyTorch 框架数据加载的关键实体进行分析。

  <h3 class="title">Python 中的迭代</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;理解 Python 中与迭代相关的概念，是理解 <code>torch.utils.data</code> 模块中的 <b>Dataset</b>，<b>Sampler</b> 和 <b>DataLoader</b> 三个实体的关键，因此如果读者朋友对 Python 中与迭代相关的概念尚不熟悉，建议先对我的另一篇文章 <a href="/sec_learning/Tech_Program/Python_Iteration/index.html">Python 中的迭代</a> 进行阅读。

  <h3 class="title">Python 中的多进程</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;我们在后面介绍 <b>DataLoader</b> 实体的相关内容的时候将会涉及到如何基于 Python 的多进程机制加速数据加载的过程，因此需要读者对 Python 的多进程机制有一定的了解。如果您对此不是特别熟悉，建议先对我的另一篇文章 <a href="/sec_learning/Tech_Program/Python_Multiprocessing/index.html">Python 的多进程</a> 进行阅读。

  <h3 class="title">数据加载</h3>
  <label class="title">dataloading</label>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;首先，模型的训练基于数据集，因此在训练过程中，有一部分的工作是要关心数据集如何从磁盘中被加载到 Host Memory / GPU Memory，数据集如何进行采样生成 Mini-batch，生成的 Mini-batch 如何被依次送进模型中进行训练，这也就是本文要关心的训练过程中被称为 <def>Dataloading (数据加载)</def> 的环节。本文把 Dataloading 中划分出了若干功能性实体。

  <div class="img" title="训练流程中的 DataSet, DataLoader 和 Sampler" label="img_dataloading">
    <img src="./pic/workflow.png" width="90%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<imgref>img_dataloading</imgref> 展示了 Dataloading 在整个训练过程中所处的位置。首先，我们的数据集被存放在磁盘中，<def><b>Dataset</b></def> 实体用于将 Dataset 从磁盘中读取到 Host Memory 中，并且提供了用于访问 Dataset 中各条 Sample 的 Feature 和 Label 的方法 (i.e. 对于 Map-style Dataset 来说提供了 <code>__getitem__(self)</code> 魔法方法; Iterable-style Dataset 则提供了 <code>__iter__(self)</code> 魔法方法)。在训练过程中，会有多轮 Epoches，每一轮 Epoch 会有多轮 Iterations，每一轮 Iteration 一个 Mini-batch 送入模型进行前向传播、损失值计算、参数梯度计算和参数更新，在每一轮 Epoch 中会完成一次对训练集 (Mini-batches) 的遍历。为了更好的实现对 Mini-batches 的遍历的编程抽象，<def><b>DataLoader</b></def> 实体应该提供一种 <def>Iterable (可迭代)</def> 的方法，使得我们在每轮 Epoch 中可以基于 Python <code>for mini-batch in DataLoader</code> 的范式完成对 Mini-batches 的遍历。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<b>DataLoader</b> 在为某轮 Epoch 生成 Mini-batches 的过程中，是按照什么规则生成 Mini-batches 的呢？可以是按顺序在 <b>Dataset</b> 中进行采样，也可以是按照随机的规则进行采样，生成 Mini-batches 的采样规则就是由 <def><b>BatchSampler</b></def> 实体予以实现的。具体来说，<b>BatchSampler</b> 实体基于一定的采样规则，把采样生成的 Samples 的索引返回给 <b>DataLoader</b>，最后由 <b>DataLoader</b> 中的 <def><b>Fetcher</b></def> 实体完成从 <b>Dataset</b> 中提取序号对应的 Samples 下的特征和标签数据，以最终完成 Mini-batches 的生成。另外，我们把一次迭代生成一条 Sample 的索引的采样器称为 <def><b>Sampler</b></def> 实体，生成多条 Samples 的索引的采样器则称为 <b>BatchSampler</b>，我们后面会看到，PyTorch 中使用 <b>Sampler</b> 实体来设置采样的规则 (e.g. 顺序采样，随机采样，etc.)，然后再基于 <b>Sampler</b> 结合 Batch Size 等设置生成 <b>BatchSampler</b> 实体。

  <div class="background">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;综上，<b>Dataset</b>，<b>BatchSampler</b> 和 <b>DataLoader</b> 可以总结为:

  <ul>
    <li><def><b>Dataset</b></def>: 将原始存储在磁盘中的数据集读取到内存中并封装为 Python 对应的对象，并且暴露提取接口;</li>
    <li><def><b>BatchSampler</b></def>: 在每次迭代时输出当前 Iteration 所使用的 Samples 的索引;</li>
    <li><def><b>DataLoader</b></def>: 基于设置好的 <b>Dataset</b> 和 <b>BatchSampler</b> 实体，在每次迭代时，<b>DataLoader</b> 将首先迭代 <b>BatchSampler</b> 实体以获得当前 Iteration 使用的 Samples 的索引，然后调用其 <b>Fetcher</b> 实体完成对应 Samples 的特征和标签数据的组装，最后进行输出。</li>
  </ul>

  <div class="img" title="DataLoader, Sampler 和 Dataset 三者关系图">
    <img src="./pic/cooperate.png" width="700px" />
  </div>
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;下面我们分别对上述的功能性实体进行介绍。
</div> 

<h2 class="title">Dataset 功能性介绍</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<b>Dataset</b> 实体负责对来源于磁盘的 Raw Dataset 进行封装，将其封装成 Python 可识别的数据结构。<code>torch.utils.data</code> 模块提供了多种形式的 <b>Dataset</b> 实体抽象，并且分别提供了对应的接口类完成对这些类型的数据集的抽象，用户需要实现接口类中的相应接口，以完成对自定义数据集的封装。我们下面对这些数据集抽象分别进行分析。

  <div class="multi_img">
    <div class="img" title="Map-style Dataset" label="map_style_ds">
      <img src="./pic/map_style.png" height="300px" />
    </div>
    <div class="img" title="Iterable-style Dataset" label="iter_style_ds">
      <img src="./pic/iter_style.png" height="300px" />
    </div>
  </div>

  <h3 class="title">Map-style Dataset</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>torch.utils.data</code> 模块使用 <code>Dataset</code> 接口类抽象 Map-style 的数据集，Map-style 顾名思义就是数据集中的每一条 Sample 都拥有一个索引，用户可以通过索引的方式来获取 Samples。<code>Dataset</code> 的定义如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dataset</span>(<span class="params">Generic[T_co]</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>) -&gt; T_co:</span></span><br><span class="line">      <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__add__</span>(<span class="params">self, other: <span class="string">&#x27;Dataset[T_co]&#x27;</span></span>) -&gt; &#x27;ConcatDataset[T_co]&#x27;:</span></span><br><span class="line">      <span class="keyword">return</span> ConcatDataset([self, other])</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;可以发现，Map-style 的数据集通过定义 <code>__getitem__()</code> 魔法方法，实现了从索引到 Sample 的映射，使得用户可以使用 <code>dataset[idx]</code> 就可以访问 <code>idx</code> 对应的 Sample。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;细心的读者会发现在上面展示的 <code>Dataset</code> 接口类中并没有规定实现 <code>__len()__</code> 接口，原因是 <code>return NotImplemented</code> 或者 <code>raise NotImplementedError()</code> 之类的默认实现都会存在各自的问题，因此 <code>Dataset</code> 接口类把对 <code>__len()__</code> 接口的实现留给了子类。

  <h3 class="title">Iterable-style Dataset</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;Iterable-style 的数据集是一种通过实现 <code>__iter__()</code> 来获取数据的 Dataset，这种类型的数据集特别适用于以下情况: ① 像 Map-style 数据集一样基于索引随机读取的代价很大甚至不大可能；或者 ② 每轮 Iteration 所使用的 Batch Size 并不固定，而取决于获取的数据。<code>torch.utils.data</code> 模块使用 <code>IterableDataset</code> 接口类抽象 Iterable-style 的数据集，其定义如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IterableDataset</span>(<span class="params">Dataset[T_co]</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[T_co]:</span></span><br><span class="line">      <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__add__</span>(<span class="params">self, other: Dataset[T_co]</span>):</span></span><br><span class="line">      <span class="keyword">return</span> ChainDataset([self, other])</span><br></pre></td></tr></table></figure>
  <h3 class="title">其它 Dataset</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;上述的 Map-style 和 Iterable-style 的 Dataset 是 PyTorch 中两种最主要的 Dataset，下面我们介绍几种基于它们的其它 Datasets。

  <h4 class="paragraph">Concat Dataset</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>ConcatDataset</code> 被用于级联多个数据集类，使得级联出来的数据集就像是一个统一大的数据集一样，可以基于索引/关键字对 Samples 进行访问，具体定义如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConcatDataset</span>(<span class="params">Dataset[T_co]</span>):</span></span><br><span class="line">  datasets: List[Dataset[T_co]]</span><br><span class="line">  cumulative_sizes: List[<span class="built_in">int</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">  @staticmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">cumsum</span>(<span class="params">sequence</span>):</span></span><br><span class="line">      r, s = [], <span class="number">0</span></span><br><span class="line">      <span class="keyword">for</span> e <span class="keyword">in</span> sequence:</span><br><span class="line">          l = <span class="built_in">len</span>(e)</span><br><span class="line">          r.append(l + s)</span><br><span class="line">          s += l</span><br><span class="line">      <span class="keyword">return</span> r</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, datasets: Iterable[Dataset]</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">      <span class="built_in">super</span>(ConcatDataset, self).__init__()</span><br><span class="line">      self.datasets = <span class="built_in">list</span>(datasets)</span><br><span class="line">      <span class="keyword">assert</span> <span class="built_in">len</span>(self.datasets) &gt; <span class="number">0</span>, <span class="string">&#x27;datasets should not be an empty iterable&#x27;</span>  <span class="comment"># type: ignore[arg-type]</span></span><br><span class="line">      <span class="keyword">for</span> d <span class="keyword">in</span> self.datasets:</span><br><span class="line">          <span class="keyword">assert</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(d, IterableDataset), <span class="string">&quot;ConcatDataset does not support IterableDataset&quot;</span></span><br><span class="line">      self.cumulative_sizes = self.cumsum(self.datasets)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="keyword">return</span> self.cumulative_sizes[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">      <span class="keyword">if</span> idx &lt; <span class="number">0</span>:</span><br><span class="line">          <span class="keyword">if</span> -idx &gt; <span class="built_in">len</span>(self):</span><br><span class="line">              <span class="keyword">raise</span> ValueError(<span class="string">&quot;absolute value of index should not exceed dataset length&quot;</span>)</span><br><span class="line">          idx = <span class="built_in">len</span>(self) + idx</span><br><span class="line">      dataset_idx = bisect.bisect_right(self.cumulative_sizes, idx)</span><br><span class="line">      <span class="keyword">if</span> dataset_idx == <span class="number">0</span>:</span><br><span class="line">          sample_idx = idx</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          sample_idx = idx - self.cumulative_sizes[dataset_idx - <span class="number">1</span>]</span><br><span class="line">      <span class="keyword">return</span> self.datasets[dataset_idx][sample_idx]</span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">cummulative_sizes</span>(<span class="params">self</span>):</span></span><br><span class="line">      warnings.warn(<span class="string">&quot;cummulative_sizes attribute is renamed to &quot;</span></span><br><span class="line">                    <span class="string">&quot;cumulative_sizes&quot;</span>, DeprecationWarning, stacklevel=<span class="number">2</span>)</span><br><span class="line">      <span class="keyword">return</span> self.cumulative_sizes</span><br></pre></td></tr></table></figure>
  <h4 class="paragraph">Chain Dataset</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>ChainDataset</code> 被用于包含多个 <code>IterableDataset</code> 数据集，在 <code>IterableDataset</code> 的 <code>__add__()</code> 方法中被调用，具体定义如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChainDataset</span>(<span class="params">IterableDataset</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, datasets: Iterable[Dataset]</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">      <span class="built_in">super</span>(ChainDataset, self).__init__()</span><br><span class="line">      self.datasets = datasets</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="keyword">for</span> d <span class="keyword">in</span> self.datasets:</span><br><span class="line">          <span class="keyword">assert</span> <span class="built_in">isinstance</span>(d, IterableDataset), <span class="string">&quot;ChainDataset only supports IterableDataset&quot;</span></span><br><span class="line">          <span class="keyword">for</span> x <span class="keyword">in</span> d:</span><br><span class="line">              <span class="keyword">yield</span> x</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">      total = <span class="number">0</span></span><br><span class="line">      <span class="keyword">for</span> d <span class="keyword">in</span> self.datasets:</span><br><span class="line">          <span class="keyword">assert</span> <span class="built_in">isinstance</span>(d, IterableDataset), <span class="string">&quot;ChainDataset only supports IterableDataset&quot;</span></span><br><span class="line">          total += <span class="built_in">len</span>(d)  <span class="comment"># type: ignore[arg-type]</span></span><br><span class="line">      <span class="keyword">return</span> total</span><br></pre></td></tr></table></figure>
  <h4 class="paragraph">Subset Dataset</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>Subset</code> 被用于将原有数据集指定下标的 Samples 封装为一个新的数据集，具体定义如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Subset</span>(<span class="params">Dataset[T_co]</span>):</span></span><br><span class="line">  dataset: Dataset[T_co]</span><br><span class="line">  indices: Sequence[<span class="built_in">int</span>]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dataset: Dataset[T_co], indices: Sequence[<span class="built_in">int</span>]</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">      self.dataset = dataset</span><br><span class="line">      self.indices = indices</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">      <span class="keyword">if</span> <span class="built_in">isinstance</span>(idx, <span class="built_in">list</span>):</span><br><span class="line">          <span class="keyword">return</span> self.dataset[[self.indices[i] <span class="keyword">for</span> i <span class="keyword">in</span> idx]]</span><br><span class="line">      <span class="keyword">return</span> self.dataset[self.indices[idx]]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">len</span>(self.indices)</span><br></pre></td></tr></table></figure>
  <h4 class="paragraph">Tensor Dataset</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>TensorDataset</code> 用于获取封装成 Tensor 的数据集，每一个样本都通过索引张量来获得，具体代码如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TensorDataset</span>(<span class="params">Dataset[Tuple[Tensor, ...]]</span>):</span></span><br><span class="line">  tensors: Tuple[Tensor, ...]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *tensors: Tensor</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">      <span class="keyword">assert</span> <span class="built_in">all</span>(tensors[<span class="number">0</span>].size(<span class="number">0</span>) == tensor.size(<span class="number">0</span>) <span class="keyword">for</span> tensor <span class="keyword">in</span> tensors), <span class="string">&quot;Size mismatch between tensors&quot;</span></span><br><span class="line">      self.tensors = tensors</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">tuple</span>(tensor[index] <span class="keyword">for</span> tensor <span class="keyword">in</span> self.tensors)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="keyword">return</span> self.tensors[<span class="number">0</span>].size(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
</div>

<h2 class="title">BatchSampler 功能性介绍</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;现在我们定义好了 <b>Dataset</b> 实体抽象，已经拥有了一些接口可以获取 <b>Dataset</b> 中各条 Samples。在训练的各轮 Epoches 中，我们需要在每轮 Iteration 中从 <b>Dataset</b> 中读取单条 Sample (或多条 Samples 以形成 Mini-batch) 对模型进行训练，那么应该按照什么顺序来读取 <b>Dataset</b> 中的内容以形成这些 Mini-batches 呢？这也就是我们本节要讨论的 <b>BatchSampler</b> 实体抽象的工作。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 Map-style Dataset 来说，如 <imgref>map_style_ds</imgref> 所示，每一条 Sample 都会有一个索引，<b>BatchSampler</b> 的功能就是在每轮 Epoch 的每轮 Iteration 中输出参与训练的 Samples 的 索引。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;而对于 Iteration-style Dataset 来说，如 <imgref>iter_style_ds</imgref> 所示，每一条 Sample 并不会有索引。正如我们上面所述，Iteration-style Dataset 需要基于 Iterator 的方法来完成对数据集中的 Samples 的访问，因此对 Iteration-style Dataset 中 Samples 的遍历顺序完全由其 Iterator 定义的 <code>__next__(self)</code> 魔法方法定义的访问顺序决定，因此本节讨论的 <b>BatchSampler</b> 实体并不对 Iteration-style Dataset 有效，因此<note>我们默认本章剩余篇幅讨论的都是 Map-style Dataset</note>。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;回顾我们在 <ref>dataloading</ref> 中描述的，<b>Sampler</b> 实体每次迭代输出一条 Sample 的索引，而 <b>BatchSampler</b> 实体每次迭代则输出多条 Samples 的索引。在 PyTorch 的实现中，通常实现定义出 <b>Sampler</b> 实体，以确定采样规则 (e.g. 随机采样，顺序采样，etc.)，然后再基于定义好的 <b>Sampler</b> 实体结合 Batch Size 等设置生成 <b>BatchSampler</b> 实体。

  <h3 class="title">Sampler 实体</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;我们下面首先来看 <b>Sampler</b> 实体的实现。在 <code>torch.utils.data</code> 模块中，<code>Sampler</code> 类定义了 <b>Sampler</b> 实体所应该拥有的接口，定义如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sampler</span>(<span class="params">Generic[T_co]</span>):</span></span><br><span class="line">  <span class="string">r&quot;&quot;&quot;Base class for all Samplers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Every Sampler subclass has to provide an :meth:`__iter__` method, providing a</span></span><br><span class="line"><span class="string">  way to iterate over indices of dataset elements, and a :meth:`__len__` method</span></span><br><span class="line"><span class="string">  that returns the length of the returned iterators.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  .. note:: The :meth:`__len__` method isn&#x27;t strictly required by</span></span><br><span class="line"><span class="string">            :class:`~torch.utils.data.DataLoader`, but is expected in any</span></span><br><span class="line"><span class="string">            calculation involving the length of a :class:`~torch.utils.data.DataLoader`.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_source: Optional[Sized]</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">      <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[T_co]:</span></span><br><span class="line">      <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;从上面的代码和注释中可以看到，<b>Sampler</b> 实体需要定义 <code>__iter__(self)</code> 魔法方法，以可以通过 <code>iter()</code> 的方法来获得 <b>Sampler</b> 的 Iterator，对 Iterator 进行的每次迭代可以得到的采样得到的单条 Sample 的序号。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;基于 <code>Sampler</code> 接口类，<code>torch.utils.data</code> 模块中提供了多种内置的 <b>Sampler</b> 实现，下面我们展示了其中的 <code>RandomSampler</code> 的相关定义。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomSampler</span>(<span class="params">Sampler[<span class="built_in">int</span>]</span>):</span></span><br><span class="line">  <span class="string">r&quot;&quot;&quot;Samples elements randomly. If without replacement, then sample from a shuffled dataset.</span></span><br><span class="line"><span class="string">  If with replacement, then user can specify :attr:`num_samples` to draw.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">      data_source (Dataset): dataset to sample from</span></span><br><span class="line"><span class="string">      replacement (bool): samples are drawn on-demand with replacement if ``True``, default=``False``</span></span><br><span class="line"><span class="string">      num_samples (int): number of samples to draw, default=`len(dataset)`.</span></span><br><span class="line"><span class="string">      generator (Generator): Generator used in sampling.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  data_source: Sized</span><br><span class="line">  replacement: <span class="built_in">bool</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_source: Sized, replacement: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               num_samples: Optional[<span class="built_in">int</span>] = <span class="literal">None</span>, generator=<span class="literal">None</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">      self.data_source = data_source</span><br><span class="line">      self.replacement = replacement</span><br><span class="line">      self._num_samples = num_samples</span><br><span class="line">      self.generator = generator</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(self.replacement, <span class="built_in">bool</span>):</span><br><span class="line">          <span class="keyword">raise</span> TypeError(<span class="string">&quot;replacement should be a boolean value, but got &quot;</span></span><br><span class="line">                          <span class="string">&quot;replacement=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(self.replacement))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(self.num_samples, <span class="built_in">int</span>) <span class="keyword">or</span> self.num_samples &lt;= <span class="number">0</span>:</span><br><span class="line">          <span class="keyword">raise</span> ValueError(<span class="string">&quot;num_samples should be a positive integer &quot;</span></span><br><span class="line">                           <span class="string">&quot;value, but got num_samples=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(self.num_samples))</span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">num_samples</span>(<span class="params">self</span>) -&gt; int:</span></span><br><span class="line">      <span class="comment"># dataset size might change at runtime</span></span><br><span class="line">      <span class="keyword">if</span> self._num_samples <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">          <span class="keyword">return</span> <span class="built_in">len</span>(self.data_source)</span><br><span class="line">      <span class="keyword">return</span> self._num_samples</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[int]:</span></span><br><span class="line">      n = <span class="built_in">len</span>(self.data_source)</span><br><span class="line">      <span class="keyword">if</span> self.generator <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">          seed = <span class="built_in">int</span>(torch.empty((), dtype=torch.int64).random_().item())</span><br><span class="line">          generator = torch.Generator()</span><br><span class="line">          generator.manual_seed(seed)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          generator = self.generator</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> self.replacement:</span><br><span class="line">          <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.num_samples // <span class="number">32</span>):</span><br><span class="line">              <span class="keyword">yield</span> <span class="keyword">from</span> torch.randint(high=n, size=(<span class="number">32</span>,), dtype=torch.int64, generator=generator).tolist()</span><br><span class="line">          <span class="keyword">yield</span> <span class="keyword">from</span> torch.randint(high=n, size=(self.num_samples % <span class="number">32</span>,), dtype=torch.int64, generator=generator).tolist()</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.num_samples // n):</span><br><span class="line">              <span class="keyword">yield</span> <span class="keyword">from</span> torch.randperm(n, generator=generator).tolist()</span><br><span class="line">          <span class="keyword">yield</span> <span class="keyword">from</span> torch.randperm(n, generator=generator).tolist()[:self.num_samples % n]</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>) -&gt; int:</span></span><br><span class="line">      <span class="keyword">return</span> self.num_samples</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在 <code>RandomSampler</code> 的 <code>__iter__(self)</code> 魔法方法中我们可以看到，其返回的实际上是一个 Generator，采用 on-the-fly 的方式，随机地，可支持有放回地生成 Sample 的采样序号。

  <h3 class="title">BatchSampler 实体</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在 <code>torch.utils.data</code> 模块中，<code>BatchSampler</code> 类实现了 <b>BatchSampler</b> 实体所应该拥有的接口，定义如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BatchSampler</span>(<span class="params">Sampler[List[<span class="built_in">int</span>]]</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Wraps another sampler to yield a mini-batch of indices.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        sampler (Sampler or Iterable): Base sampler. Can be any iterable object</span></span><br><span class="line"><span class="string">        batch_size (int): Size of mini-batch.</span></span><br><span class="line"><span class="string">        drop_last (bool): If ``True``, the sampler will drop the last batch if</span></span><br><span class="line"><span class="string">            its size would be less than ``batch_size``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Example:</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))</span></span><br><span class="line"><span class="string">        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))</span></span><br><span class="line"><span class="string">        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, sampler: Union[Sampler[<span class="built_in">int</span>], Iterable[<span class="built_in">int</span>]], batch_size: <span class="built_in">int</span>, drop_last: <span class="built_in">bool</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="comment"># Since collections.abc.Iterable does not check for `__getitem__`, which</span></span><br><span class="line">        <span class="comment"># is one way for an object to be an iterable, we don&#x27;t do an `isinstance`</span></span><br><span class="line">        <span class="comment"># check here.</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(batch_size, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(batch_size, <span class="built_in">bool</span>) <span class="keyword">or</span> \</span><br><span class="line">                batch_size &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;batch_size should be a positive integer value, &quot;</span></span><br><span class="line">                            <span class="string">&quot;but got batch_size=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(batch_size))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(drop_last, <span class="built_in">bool</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;drop_last should be a boolean value, but got &quot;</span></span><br><span class="line">                            <span class="string">&quot;drop_last=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(drop_last))</span><br><span class="line">        self.sampler = sampler</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.drop_last = drop_last</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[List[int]]:</span></span><br><span class="line">        <span class="comment"># Implemented based on the benchmarking in https://github.com/pytorch/pytorch/pull/76951</span></span><br><span class="line">        <span class="keyword">if</span> self.drop_last:</span><br><span class="line">            sampler_iter = <span class="built_in">iter</span>(self.sampler)</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    batch = [<span class="built_in">next</span>(sampler_iter) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.batch_size)]</span><br><span class="line">                    <span class="keyword">yield</span> batch</span><br><span class="line">                <span class="keyword">except</span> StopIteration:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            batch = [<span class="number">0</span>] * self.batch_size</span><br><span class="line">            idx_in_batch = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> idx <span class="keyword">in</span> self.sampler:</span><br><span class="line">                batch[idx_in_batch] = idx</span><br><span class="line">                idx_in_batch += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> idx_in_batch == self.batch_size:</span><br><span class="line">                    <span class="keyword">yield</span> batch</span><br><span class="line">                    idx_in_batch = <span class="number">0</span></span><br><span class="line">                    batch = [<span class="number">0</span>] * self.batch_size</span><br><span class="line">            <span class="keyword">if</span> idx_in_batch &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">yield</span> batch[:idx_in_batch]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>) -&gt; int:</span></span><br><span class="line">        <span class="comment"># Can only be called if self.sampler has __len__ implemented</span></span><br><span class="line">        <span class="comment"># We cannot enforce this condition, so we turn off typechecking for the</span></span><br><span class="line">        <span class="comment"># implementation below.</span></span><br><span class="line">        <span class="comment"># Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]</span></span><br><span class="line">        <span class="keyword">if</span> self.drop_last:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(self.sampler) // self.batch_size  <span class="comment"># type: ignore[arg-type]</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="built_in">len</span>(self.sampler) + self.batch_size - <span class="number">1</span>) // self.batch_size  <span class="comment"># type: ignore[arg-type]</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;从上面的代码中可以看到，<code>BatchSampler</code> 定义了三个初始化参数:

  <ul>
    <li><code>sampler</code>: 当前创建的 <code>BatchSampler</code> 基于的 <b>Sampler</b>，用于确定采样的具体规则;</li>
    <li><code>batch_size</code>: 每一次对 <code>BatchSampler</code> 进行迭代 (i.e. 每一轮 Iteration) 时，<code>BatchSampler</code> 要输出的 Samples 的索引的数目;</li>
    <li><code>drop_last</code>: 布尔变量，指示是否丢弃最后一个规模达不到 <code>batch_size</code> 的 Mini-batch;</li>
  </ul>
</div>

<h2 class="title">DataLoader 功能性介绍</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;铺垫完了 <b>Dataset</b> 和 <b>BatchSampler</b> 两个实体后，现在我们来到了数据加载流程的核心 —— <b>DataLoader</b>。<code>torch.utils.data</code> 提供的 <code>DataLoader</code> 是 PyTorch 加载数据的核心，其支持 Map-style 和 Iterable-style 的 <b>Dataset</b> 的数据加载，支持单进程/多进程数据加载，还可以设置 loading order, batch size, pin memory 等加载参数的设置，可以认为是数据加载流程的统一入口。

  <h3 class="title">DataLoader 接口</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>DataLoader</code> 的接口定义如下：

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">DataLoader(</span><br><span class="line">  dataset: Dataset[T_co],</span><br><span class="line">  batch_size: Optional[<span class="built_in">int</span>] = <span class="number">1</span>,</span><br><span class="line">  shuffle: Optional[<span class="built_in">bool</span>] = <span class="literal">None</span>,</span><br><span class="line">  sampler: Union[Sampler, Iterable, <span class="literal">None</span>] = <span class="literal">None</span>,</span><br><span class="line">  batch_sampler: Union[Sampler[Sequence], Iterable[Sequence], <span class="literal">None</span>] = <span class="literal">None</span>,</span><br><span class="line">  num_workers: <span class="built_in">int</span> = <span class="number">0</span>,</span><br><span class="line">  collate_fn: Optional[_collate_fn_t] = <span class="literal">None</span>,</span><br><span class="line">  pin_memory: <span class="built_in">bool</span> = <span class="literal">False</span>,</span><br><span class="line">  drop_last: <span class="built_in">bool</span> = <span class="literal">False</span>,</span><br><span class="line">  timeout: <span class="built_in">float</span> = <span class="number">0</span>,</span><br><span class="line">  worker_init_fn: Optional[_worker_init_fn_t] = <span class="literal">None</span>,</span><br><span class="line">  multiprocessing_context=<span class="literal">None</span>,</span><br><span class="line">  generator=<span class="literal">None</span>,</span><br><span class="line">  *,</span><br><span class="line">  prefetch_factor: <span class="built_in">int</span> = <span class="number">2</span>,</span><br><span class="line">  persistent_workers: <span class="built_in">bool</span> = <span class="literal">False</span>,</span><br><span class="line">  pin_memory_device: <span class="built_in">str</span> = <span class="string">&quot;&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;接口参数整理如下所示:

  <div class="table" title="DataLoader 接口参数说明">
  <table>
    <tr>
      <th align="center">Attribute</th>
      <th align="center">Description</th>
      <th align="center">Default Value</th>
      <th align="center">Type</th>
    </tr>
    <tr>
      <td><code>dataset</code></td>
      <td>要加载的 <b>Dataset</b> 实体</td>
      <td></td>
      <td><code>Dataset</code></td>
    </tr>
    <tr>
      <td><code>batch_size</code></td>
      <td>每轮 Iteration 要加载的 Samples 的数目</td>
      <td>$1$</td>
      <td><code>int</code></td>
    </tr>
    <tr>
      <td><code>shuffle</code></td>
      <td>设置为 <code>True</code> 时，将调用 <code>RandomSampler</code> 进行随机索引</td>
      <td><code>False</code></td>
      <td><code>bool</code></td>
    </tr>
    <tr>
      <td><code>sampler</code></td>
      <td>用户指定的 <b>Sampler</b> 实体，定义从 <note>Map-style</note> Dataset 中提取样本的策略，每一次 <code>yield</code> <note>一条</note> Sample 的索引。如果指定了 <code>sampler</code>, 则上述 <code>shuffle</code> 参数必须为 <code>False</code>，否则会和 <code>RandomSampler</code> 互斥</td>
      <td><code>None</code></td>
      <td><code>Sampler</code>, <code>Iterable</code></td>
    </tr>
    <tr>
      <td><code>batch_sampler</code></td>
      <td>用户指定的 <b>BatchSampler</b> 实体，定义从 <note>Map-style</note> Dataset 中提取样本的策略，每一次 <code>yield</code> <note>多条</note> Samples 的索引</td>
      <td><code>None</code></td>
      <td><code>Sampler</code>, <code>Iterable</code></td>
    </tr>
    <tr>
      <td><code>num_workers</code></td>
      <td>要用于数据加载的子进程数，$0$ 表示仅在主进程中加载数据</td>
      <td>$0$</td>
      <td><code>int</code></td>
    </tr>
    <tr>
      <td><code>collate_fn</code></td>
      <td>在将 Map-style Dataset 取出的数据整合成最终 Mini-batch 时使用</td>
      <td><code>None</code></td>
      <td><code>callable</code></td>
    </tr>
    <tr>
      <td><code>pin_memory</code></td>
      <td>如果为 <code>True</code>，则 <code>DataLoader</code> 在将张量返回之前将其复制到 CUDA 的锁页内存中</td>
      <td><code>False</code></td>
      <td><code>bool</code></td>
    </tr>
    <tr>
      <td><code>drop_last</code></td>
      <td>若设置为 <code>True</code>，则当该数据集大小 (i.e. <code>len(dataset)</code>) 不能被该批次大小 (i.e. <code>batch_size</code>) 整除时，删除最后一个不完整的批次；如果为 <code>False</code> 并且数据集的大小不能被批次大小整除，那么最后一批将较小</td>
      <td><code>False</code></td>
      <td><code>bool</code></td>
    </tr>
    <tr>
      <td><code>timeout</code></td>
      <td>如果为正数，则为从 Worker 构建 Mini-batch 的超时值，应始终为非负数。超过这个时间还没从 Worker 读取到数据的话就会报错</td>
      <td>$0$</td>
      <td><code>numeric</code></td>
    </tr>
    <tr>
      <td><code>worker_init_fn</code></td>
      <td>如果不为 <code>None</code>，它将会被每个 Worker 子进程调用。该函数将以 Worker Index (i.e. [0, <code>num_workers</code> - 1] 内的整形) 作为输入</td>
      <td><code>None</code></td>
      <td><code>callable</code></td>
    </tr>
    <tr>
      <td><code>prefetch_factor</code></td>
      <td>每个 Worker 提前加载的 Sample 数量</td>
      <td>$2$</td>
      <td><code>int</code></td>
    </tr>
    <tr>
      <td><code>persistent_workers</code></td>
      <td>如果为 <code>True</code>，则 <code>DataLoader</code> 将不会终止 Worker 进程，直到对 <b>Dataset</b> 的迭代完成</td>
      <td><code>False</code></td>
      <td><code>bool</code></td>
    </tr>
  </table>
  </div>

  <h3 class="title">自动化批处理 (Automatic Batching)</h3>
  <div class="img" title="自动批处理流程">
    <img src="./pic/dataloader_wf.png" width="90%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>DataLoader</code> 非常方便地为用户提供了 <def>自动化批处理 (Automatic Batching)</def> 的功能，通过指定我们上面看到的相关接口中的参数，用户可以自定义出他们想要的 <b>DataLoader</b> 实体，然后在训练主进程中通过迭代的方式获取每轮 Iteration 指定规模和指定顺序的 Samples。我们可以把自动化批处理的设置氛围两个部分: ① 设置 BatchSampler; 以及 ② 设置基于 Sampled Indices 合成 Mini-batch 的方法，我们下面分别进行介绍。

  <h4 class="paragraph">设置 BatchSampler</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;基于 SGD 的训练思路，通常在一轮 Iteration 中会使用多个 Samples 组成的 Mini-batch 进行训练，而通常不会只有一条 Sample 参与训练，<code>DataLoader</code> 提供了相关的参数进行 <b>BatchSampler</b> 相关的设置:

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 Map-style Dataset 和 Iterable-style Dataset 来说，当 <code>batch_size</code> (默认为 $1$) 不为 <code>None</code> 时，生成的 <b>DataLoader</b> 在每一次被迭代时将 <code>yield</code> 出一批 Samples，而不只是一个单独的 Sample，该参数与 <code>drop_last</code> 和 <code>shuffle</code> 参数配合，将决定每一轮 Iteration 所使用的 Samples 的顺序和数目。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在 <code>DataLoader</code> 的构造函数中，相关代码会基于 <code>batch_size</code> 和 <code>drop_last</code> 参数，结合用户指定的 <b>Sampler</b> 实体构造出对应的 <b>BatchSampler</b> 实体。那么 <b>Sampler</b> 实体是如何被指定的呢？对于 Map-style Dataset 来说，可以通过两种方式被指定: 一种是通过 <code>sampler</code> 参数显式指定 <b>Sampler</b>，一种是通过 <code>shuffle</code> 参数，当它为 <code>True</code> 时使用 <code>RandomSampler</code>; 而对于 Iterable-style Dataset 来说，<b>Sampler</b> 实体并无意义，为了实现代码的兼容性，<code>DataLoader</code> 的构造函数会使用专门针对于 <code>Iterable-style Dataset</code> 提供的 Dummy Infinite Sampler <code>_InfiniteConstantSampler</code> 以充当 <b>Sampler</b> 实体，该 <b>Sampler</b> 可以无限地被迭代，其实质上是调用了 Iterable-style Dataset 的 <code>__iter__(self)</code> 魔法方法。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;单独对于 Map-style Dataset 来说，用户还可以使用 <code>batch_sampler</code> 参数来直接设置 Mini-batch 的 <b>BatchSampler</b>。

  <h4 class="paragraph">设置基于 Sampled Indices 合成 Mini-batch 的方法</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在基于指定的 <b>BatchSampler</b> 实体 <code>yield</code> 出一批某轮 Iteration 使用的 Samples 的 Indices 后，接下来就需要由 <code>collate_fn</code> 参数指定的 <def>Collate Function (整理函数)</def> 基于指定的 Indices 对应的 Samples 数据合成最终的 Mini-batch。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 Map-style Dataset 来说，Collate Function 流程可以抽象如下:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> indices <span class="keyword">in</span> batch_sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn([dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 Iteration-style Dataset 来说，Collate Function 流程可以抽象如下:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"><span class="keyword">for</span> indices <span class="keyword">in</span> batch_sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn([<span class="built_in">next</span>(dataset_iter) <span class="keyword">for</span> _ <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;具体的 Collate Function 的详细设置细节可见 <ref>collate</ref>。

  <h3 class="title">关闭自动批处理</h3>
  <div class="img" title="关闭自动批处理流程">
    <img src="./pic/dataloader_wf_1.png" width="90%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;当用户想用 <b>Dataset</b> 的代码手动处理 Batch，或每轮 Iteration 仅基于单条 Sample 进行训练时，可将 <code>batch_size</code> 和 <code>batch_sampler</code> 两个参数同时设为 <code>None</code>, 此时 <code>DataLoader</code> 将关闭自动批处理，对 <code>DataLoader</code> 的迭代将使得其通过 <b>Sampler</b> 实体获得单条 Sample 的索引，然后将该索引对应的 Sample 数据交给 <code>collate_fn</code> 处理，以获得最终的 <code>DataLoader</code> 输出。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 Map-style Dataset 来说，Collate Function 流程可以抽象如下:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn(dataset[index])</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 Iteration-style Dataset 来说，Collate Function 流程可以抽象如下:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> <span class="built_in">iter</span>(dataset):</span><br><span class="line">    <span class="keyword">yield</span> collate_fn(data)</span><br></pre></td></tr></table></figure>
  <h3 class="title">Collate Function</h3>
  <label class="title">collate</label>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;上面说到，Collate Function 的输入是从 <b>Dataset</b> 实体中获取的 Sample(s) 的数据，其输出就是对 <code>DataLoader</code> 迭代所获得的输出，在开启/关闭自动批处理时，它的运行逻辑稍有不同。

  <h4 class="paragraph">关闭自动批处理时的情况</h4>

  <div class="img" title="关闭自动批处理的 Collate 函数 (以各条 Sample 的形式是 dict 为例)" label="img_batch_collate_single" >
    <img src="./pic/collate_single.png" width="90%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;如 <imgref>img_batch_collate_single</imgref> 所示，当关闭自动批处理时，<code>collate_fn</code> 仅作用于单个 Sample，其工作就是简单地将 NumPy <code>arrays</code> 转化为 PyTorch 的 <code>Tensor</code>，在转换过程中保留了 Sample 原有的数据结构，图中展示了当 Sample 的数据结构是 <code>dict</code> 时的情况。

  <h4 class="paragraph">开启自动批处理时的情况</h4>

  <div class="img" title="开启自动批处理的 Collate 函数 (以各条 Sample 的形式是 dict 为例)" label="img_batch_collate" >
    <img src="./pic/collate.png" width="90%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;而当开启自动批处理时，如 <imgref>img_batch_collate</imgref> 所示，<code>collate_fn</code> 作用于多个 Samples，其将输入样本整理为一个 Batch，并将其 <code>yield</code> 回当前轮次的 Itertaion 以供训练。为了将输入样本整理为一个 Batch，<code>collate_fn</code> 的默认值 <code>default_collate()</code> 做了下面 $3$ 件事情:

  <ul>
    <li>追加 (Prepend) 一个新的维度作为 Batch Dimension (长度即为 Batch 的大小);</li>
    <li>将 NumPy <code>arrays</code> 和 Python Numberical Values 转化为 PyTorch 的 <code>Tensor</code>;</li>
    <li>保留输入的 Samples 中各条 Sample 的数据结构，如 <imgref>img_batch_collate</imgref> 所示，比如各条 Sample 是 <code>dict</code> 时，<code>default_collate()</code> 将输出具有相同 Keys，且处理过的 Batched Tensor (或 Batched List，当无法转化为 Tensor 的时候) 作为值的 <code>dict</code>。当各条 Sample 是 <code>list</code>、<code>tuple</code> 和 <code>namedtuple</code> 等时同理;</li>
  </ul>

  <h3 class="title">单进程数据加载</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;当设置 <code>DataLoader</code> 的 <code>num_workers</code> 为 $0$ (默认值) 时，则 <code>DataLoader</code> 的初始化进程和读取数据的进程是一样的，此时数据加载可能会导致主进程阻塞。当用于在进程之间共享数据的资源 (例如共享内存，文件描述符) 有限时，或者当整个数据集很小并且可以完全加载到内存中时，此模式可能是首选。此外，单进程加载通常显示更多可读的错误跟踪，因此对于调试很有用。

  <h3 class="title">多进程数据加载</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在多进程模式下，每轮 Iteration 开始时对 <code>DataLoader</code> 进行迭代时，都会创建 <code>num_workers</code> 个 <def>工作进程 (Worker)</def>，<code>dataset</code>, <code>collate_fn</code>, <code>worker_init_fn</code> 等参数都会被传到各个 Worker 中，各个 Worker 使用这些参数进行初始化和数据的读取和整理。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>torch.utils.data</code> 模块提供了 <code>get_work_info</code> 函数用于在各个 Worker 进程中获取各个进程相关的信息，包括 Worker 的 ID，Dataset 的 Replica，以及 Initial Seed 等，在主进程而不是 Worker 进程中调用 <code>get_work_info</code> 函数将返回 <code>None</code>。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 Map-style 的 Dataset 来说，主进程将会利用 <b>Sampler</b> (<b>BatchSampler</b>) 实体生成 Indices，然后将生成的 Indices 发送给各个 Worker 进程，也即「选择 Sample」这件事情是在主进程完成的，而「根据选择结果加载数据」这件事情是在各个 Worker 进程中完成的。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 Iterable-style 的 Dataset 来说，主进程中将不会进行生成 Indices 的操作，在各个 Worker 进程中会有一份 Dataset 的 Replica，各个 Worker 进程可以基于 <code>get_work_info</code> 函数获得的信息，对各份 Replica 进行不同的操作。

  <h3 class="title">Pinned Memory (锁页内存)</h3>
  <label class="title">pinned_memory</label>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;我的另一篇文章 <a href="/sec_learning/Tech_OS_And_Linux_Kernel/CUDA_Memory_Management/index.html">CUDA 内存管理</a> 对 CUDA Pinned Memory 相关内容进行了介绍，如果您相关内容不熟悉，可以先移步阅读。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;Host Memory 中的 Memory Page 有两种存在方式，一是 <def>锁页 (Pinned)</def>，二是 <def>不锁页 (Unpinned)</def>，锁页内存存放的内容在任何情况下都不会与主机的虚拟内存进行交换，而不锁页内存在主机内存不足时，数据会存放在虚拟内存中。主机在向 GPU 拷贝数据时，CUDA 要求数据必须放在 Pinned Host Memory 中，因此如果数据不在 Pinned Memory 中，会在 Host Memory 中经历从 Unpinned Memory 到 Pinned Memory 的拷贝过程。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pin_memory</span>(<span class="params">data, device=<span class="literal">None</span></span>):</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">isinstance</span>(data, torch.Tensor):</span><br><span class="line">      <span class="keyword">return</span> data.pin_memory(device)</span><br><span class="line">  <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, string_classes):</span><br><span class="line">      <span class="keyword">return</span> data</span><br><span class="line">  <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, collections.abc.Mapping):</span><br><span class="line">      <span class="keyword">try</span>:</span><br><span class="line">          <span class="keyword">return</span> <span class="built_in">type</span>(data)(&#123;k: pin_memory(sample, device) <span class="keyword">for</span> k, sample <span class="keyword">in</span> data.items()&#125;)  <span class="comment"># type: ignore[call-arg]</span></span><br><span class="line">      <span class="keyword">except</span> TypeError:</span><br><span class="line">          <span class="comment"># The mapping type may not support `__init__(iterable)`.</span></span><br><span class="line">          <span class="keyword">return</span> &#123;k: pin_memory(sample, device) <span class="keyword">for</span> k, sample <span class="keyword">in</span> data.items()&#125;</span><br><span class="line">  <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, <span class="built_in">tuple</span>) <span class="keyword">and</span> <span class="built_in">hasattr</span>(data, <span class="string">&#x27;_fields&#x27;</span>):  <span class="comment"># namedtuple</span></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">type</span>(data)(*(pin_memory(sample, device) <span class="keyword">for</span> sample <span class="keyword">in</span> data))</span><br><span class="line">  <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, <span class="built_in">tuple</span>):</span><br><span class="line">      <span class="keyword">return</span> [pin_memory(sample, device) <span class="keyword">for</span> sample <span class="keyword">in</span> data]  <span class="comment"># Backwards compatibility.</span></span><br><span class="line">  <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, collections.abc.Sequence):</span><br><span class="line">      <span class="keyword">try</span>:</span><br><span class="line">          <span class="keyword">return</span> <span class="built_in">type</span>(data)([pin_memory(sample, device) <span class="keyword">for</span> sample <span class="keyword">in</span> data])  <span class="comment"># type: ignore[call-arg]</span></span><br><span class="line">      <span class="keyword">except</span> TypeError:</span><br><span class="line">          <span class="comment"># The sequence type may not support `__init__(iterable)` (e.g., `range`).</span></span><br><span class="line">          <span class="keyword">return</span> [pin_memory(sample, device) <span class="keyword">for</span> sample <span class="keyword">in</span> data]</span><br><span class="line">  <span class="keyword">elif</span> <span class="built_in">hasattr</span>(data, <span class="string">&quot;pin_memory&quot;</span>):</span><br><span class="line">      <span class="keyword">return</span> data.pin_memory()</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;PyTorch 为存储在 Host Memory 中的 Tensor 提供了 <code>pin_memory()</code> 方法，其定义如上所示，该方法返回操作的 Tensor 的副本，并将数据放在 Pinned Memory 中。对于放在 Pinned Memory 中的 Tensor，用户可以使用 <def>异步 GPU 拷贝 (Asynchronous GPU copies</def> 以将 Tensor 拷贝至 GPU 内存中，做法是在 Tensor 的 <code>to()</code> 方法中加上参数 <code>non_blocking=True</code>，以实现数据传输和 Host 计算两者的 Overlapping <cite>torch_pinned_memory</cite>。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 <code>DataLoader</code> 来说，我们可以设置传入参数 <code>pin_memory=True</code>，以设置 <code>DataLoader</code> 将每次迭代返回的 Tensor 都放置到 Pinned Memory 中，以缩减数据在 Host Memory 和 GPU Memory 之间的拷贝时间。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;另外，从上面关于 <code>pin_memory()</code> 方法的代码定义中可以看到，如果传入该函数的是一个自定义的数据类型，则该函数会直接返回该数据，而不做任何 Pinning 相关的处理。对于 <code>DataLoader</code> 来说，当我们使用 <code>collate_fn</code> 指定了自定义的整理函数并且该整理函数返回了自定义类型的 Batch 数据，则当我们指定 <code>DataLoader</code> 的 <code>pin_memory=True</code> 时，则会导致 Memory Pinning 的操作并不会生效的情况。为了解决这种情况，我们需要手动地为传入 <code>collate_fn</code> 的数据添加与 Memory Pinning 相关的代码，具体示例代码如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleCustomBatch</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        transposed_data = <span class="built_in">list</span>(<span class="built_in">zip</span>(*data))</span><br><span class="line">        self.inp = torch.stack(transposed_data[<span class="number">0</span>], <span class="number">0</span>)</span><br><span class="line">        self.tgt = torch.stack(transposed_data[<span class="number">1</span>], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># custom memory pinning method on custom type</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pin_memory</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.inp = self.inp.pin_memory()</span><br><span class="line">        self.tgt = self.tgt.pin_memory()</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_wrapper</span>(<span class="params">batch</span>):</span></span><br><span class="line">    <span class="keyword">return</span> SimpleCustomBatch(batch)</span><br><span class="line"></span><br><span class="line">inps = torch.arange(<span class="number">10</span> * <span class="number">5</span>, dtype=torch.float32).view(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line">tgts = torch.arange(<span class="number">10</span> * <span class="number">5</span>, dtype=torch.float32).view(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line">dataset = TensorDataset(inps, tgts)</span><br><span class="line"></span><br><span class="line">loader = DataLoader(dataset, batch_size=<span class="number">2</span>, collate_fn=collate_wrapper,</span><br><span class="line">                    pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_ndx, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">    print(sample.inp.is_pinned())</span><br><span class="line">    print(sample.tgt.is_pinned())</span><br></pre></td></tr></table></figure>
</div>

<h2 class="title">DataLoader 源码解析</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;基于上一节对 PyTorch 提供的 <code>DataLoader</code> 有了功能性的认识后，本节我们将对其源码按顺序进行分析。

  <h3 class="title">对 <code>DataLoader</code> 进行迭代</h3>

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> data, label <span class="keyword">in</span> train_loader:</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;首先在主进程中，我们会使用如上所示的代码对 <code>DataLoader</code> 进行遍历，此时会调用它的 <code>__iter__(self)</code> 魔法方法，该方法定义如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataLoader</span>(<span class="params">Generic[T_co]</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>) -&gt; &#x27;_BaseDataLoaderIter&#x27;:</span></span><br><span class="line">      <span class="keyword">if</span> self.persistent_workers <span class="keyword">and</span> self.num_workers &gt; <span class="number">0</span>:</span><br><span class="line">          <span class="comment"># 对于多进程数据加载的情况</span></span><br><span class="line">          <span class="keyword">if</span> self._iterator <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">              <span class="comment"># 第一次发起遍历，则创建 iterator</span></span><br><span class="line">              self._iterator = self._get_iterator()</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">              <span class="comment"># 不是第一次发起遍历，则重置 iterator</span></span><br><span class="line">              self._iterator._reset(self)</span><br><span class="line">          <span class="keyword">return</span> self._iterator</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          <span class="comment"># 对于多进程数据加载的情况</span></span><br><span class="line">          <span class="keyword">return</span> self._get_iterator()</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在上面的代码中可以看见其调用了 <code>DataLoader</code> 类下的 <code>_get_iterator</code> 获取 Iterator，具体代码如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataLoader</span>(<span class="params">Generic[T_co]</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_get_iterator</span>(<span class="params">self</span>) -&gt; &#x27;_BaseDataLoaderIter&#x27;:</span></span><br><span class="line">      <span class="keyword">if</span> self.num_workers == <span class="number">0</span>:</span><br><span class="line">          <span class="keyword">return</span> _SingleProcessDataLoaderIter(self)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          self.check_worker_number_rationality()</span><br><span class="line">          <span class="keyword">return</span> _MultiProcessingDataLoaderIter(self)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;可以看到其根据单/多进程数据读取的不同情况，返回了不同的 Iterator，我们下面分情况进行讨论。

  <h3 class="title"><code>DataLoader</code> 的 Iterator</h3>

  <h4 class="title">Iterator 基类: <code>_BaseDataLoaderIter</code> </h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;首先，不论是单进程数据加载所使用的迭代器 <code>_SingleProcessDataLoaderIter</code>，还是多进程数据加载所使用的迭代器 <code>_MultiProcessingDataLoaderIter</code>，他们都继承自 <code>_BaseDataLoaderIter</code> 基类，其源码如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_BaseDataLoaderIter</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, loader: DataLoader</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">      self._dataset = loader.dataset</span><br><span class="line">      self._shared_seed = loader._get_shared_seed()</span><br><span class="line">      <span class="keyword">if</span> <span class="built_in">isinstance</span>(self._dataset, IterDataPipe):</span><br><span class="line">          shared_rng = torch.Generator()</span><br><span class="line">          shared_rng.manual_seed(self._shared_seed)</span><br><span class="line">          self._dataset = torch.utils.data.graph_settings.apply_shuffle_seed(self._dataset, shared_rng)</span><br><span class="line">      self._dataset_kind = loader._dataset_kind</span><br><span class="line">      self._IterableDataset_len_called = loader._IterableDataset_len_called</span><br><span class="line">      self._auto_collation = loader._auto_collation</span><br><span class="line">      self._drop_last = loader.drop_last</span><br><span class="line">      self._index_sampler = loader._index_sampler</span><br><span class="line">      self._num_workers = loader.num_workers</span><br><span class="line">      self._prefetch_factor = loader.prefetch_factor</span><br><span class="line">      <span class="comment"># for other backends, pin_memory_device need to set. if not set</span></span><br><span class="line">      <span class="comment"># default behaviour is CUDA device. if pin_memory_device is selected</span></span><br><span class="line">      <span class="comment"># and pin_memory is not set, the default behaviour false.</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">len</span>(loader.pin_memory_device) == <span class="number">0</span>):</span><br><span class="line">          self._pin_memory = loader.pin_memory <span class="keyword">and</span> torch.cuda.is_available()</span><br><span class="line">          self._pin_memory_device = <span class="literal">None</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          <span class="keyword">if</span> <span class="keyword">not</span> loader.pin_memory:</span><br><span class="line">              warn_msg = (<span class="string">&quot;pin memory device is set and pin_memory flag is not used then device pinned memory won&#x27;t be used&quot;</span></span><br><span class="line">                          <span class="string">&quot;please set pin_memory to true, if you need to use the device pin memory&quot;</span>)</span><br><span class="line">              warnings.warn(warn_msg)</span><br><span class="line"></span><br><span class="line">          self._pin_memory = loader.pin_memory</span><br><span class="line">          self._pin_memory_device = loader.pin_memory_device</span><br><span class="line">      self._timeout = loader.timeout</span><br><span class="line">      self._collate_fn = loader.collate_fn</span><br><span class="line">      self._sampler_iter = <span class="built_in">iter</span>(self._index_sampler)</span><br><span class="line">      self._base_seed = torch.empty((), dtype=torch.int64).random_(generator=loader.generator).item()</span><br><span class="line">      self._persistent_workers = loader.persistent_workers</span><br><span class="line">      self._num_yielded = <span class="number">0</span></span><br><span class="line">      self._profile_name = <span class="string">&quot;enumerate(DataLoader)#&#123;&#125;.__next__&quot;</span>.<span class="built_in">format</span>(self.__class__.__name__)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>) -&gt; &#x27;_BaseDataLoaderIter&#x27;:</span></span><br><span class="line">      <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_reset</span>(<span class="params">self, loader, first_iter=<span class="literal">False</span></span>):</span></span><br><span class="line">      self._sampler_iter = <span class="built_in">iter</span>(self._index_sampler)</span><br><span class="line">      self._num_yielded = <span class="number">0</span></span><br><span class="line">      self._IterableDataset_len_called = loader._IterableDataset_len_called</span><br><span class="line">      self._shared_seed = loader._get_shared_seed()</span><br><span class="line">      <span class="keyword">if</span> <span class="built_in">isinstance</span>(self._dataset, IterDataPipe):</span><br><span class="line">          shared_rng = torch.Generator()</span><br><span class="line">          shared_rng.manual_seed(self._shared_seed)</span><br><span class="line">          self._dataset = torch.utils.data.graph_settings.apply_shuffle_seed(self._dataset, shared_rng)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_next_index</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">next</span>(self._sampler_iter)  <span class="comment"># may raise StopIteration</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_next_data</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__next__</span>(<span class="params">self</span>) -&gt; Any:</span></span><br><span class="line">      <span class="keyword">with</span> torch.autograd.profiler.record_function(self._profile_name):</span><br><span class="line">          <span class="keyword">if</span> self._sampler_iter <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">              <span class="comment"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span></span><br><span class="line">              self._reset()  <span class="comment"># type: ignore[call-arg]</span></span><br><span class="line">          data = self._next_data()</span><br><span class="line">          self._num_yielded += <span class="number">1</span></span><br><span class="line">          <span class="keyword">if</span> self._dataset_kind == _DatasetKind.Iterable <span class="keyword">and</span> \</span><br><span class="line">                  self._IterableDataset_len_called <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> \</span><br><span class="line">                  self._num_yielded &gt; self._IterableDataset_len_called:</span><br><span class="line">              warn_msg = (<span class="string">&quot;Length of IterableDataset &#123;&#125; was reported to be &#123;&#125; (when accessing len(dataloader)), but &#123;&#125; &quot;</span></span><br><span class="line">                          <span class="string">&quot;samples have been fetched. &quot;</span>).<span class="built_in">format</span>(self._dataset, self._IterableDataset_len_called,</span><br><span class="line">                                                                self._num_yielded)</span><br><span class="line">              <span class="keyword">if</span> self._num_workers &gt; <span class="number">0</span>:</span><br><span class="line">                  warn_msg += (<span class="string">&quot;For multiprocessing data-loading, this could be caused by not properly configuring the &quot;</span></span><br><span class="line">                               <span class="string">&quot;IterableDataset replica at each worker. Please see &quot;</span></span><br><span class="line">                               <span class="string">&quot;https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.&quot;</span>)</span><br><span class="line">              warnings.warn(warn_msg)</span><br><span class="line">          <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">  <span class="built_in">next</span> = __next__  <span class="comment"># Python 2 compatibility</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>) -&gt; int:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">len</span>(self._index_sampler)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__getstate__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="comment"># <span class="doctag">TODO:</span> add limited pickling support for sharing an iterator</span></span><br><span class="line">      <span class="comment"># across multiple threads for HOGWILD.</span></span><br><span class="line">      <span class="comment"># Probably the best way to do this is by moving the sample pushing</span></span><br><span class="line">      <span class="comment"># to a separate thread and then just sharing the data queue</span></span><br><span class="line">      <span class="comment"># but signalling the end is tricky without a non-blocking API</span></span><br><span class="line">      <span class="keyword">raise</span> NotImplementedError(<span class="string">&quot;&#123;&#125; cannot be pickled&quot;</span>, self.__class__.__name__)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在 <code>_BaseDataLoaderIter</code> 中定义了 <code>__next__(self)</code> 函数，我们在主进程中使用 <code>for</code> 循环迭代 <code>DataLoader</code> 时，首先其会调用 <code>DataLoader</code> 的 <code>__iter__(self)</code> 魔法方法以获得 Iterator，而 <code>DataLoader</code> 的 Iterators 实现都继承自 <code>_BaseDataLoaderIter</code>，因此在获取完 Iterator 后 <code>for</code> 循环实际上就是通过不断调用 <code>_BaseDataLoaderIter</code> 的 <code>__next__(self)</code> 以获得下一批用于训练的 Batched Tensor。从上面的代码中可以看到，<code>__next__(self)</code> 则是调用 <code>_next_data()</code> 以获取相关数据，而后者留给继承自 <code>_BaseDataLoaderIter</code> 的子类予以实现。

  <h4 class="title">单进程加载 Iterator: <code>_SingleProcessDataLoaderIter</code> 类</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在单进程数据加载的设定下，代表 Iterator 的类是  <code>_SingleProcessDataLoaderIter</code>，其定义如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_SingleProcessDataLoaderIter</span>(<span class="params">_BaseDataLoaderIter</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, loader</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(_SingleProcessDataLoaderIter, self).__init__(loader)</span><br><span class="line">        <span class="keyword">assert</span> self._timeout == <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> self._num_workers == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self._dataset_fetcher = _DatasetKind.create_fetcher(</span><br><span class="line">            self._dataset_kind, self._dataset, self._auto_collation, self._collate_fn, self._drop_last)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_next_data</span>(<span class="params">self</span>):</span></span><br><span class="line">        index = self._next_index()  <span class="comment"># may raise StopIteration</span></span><br><span class="line">        data = self._dataset_fetcher.fetch(index)  <span class="comment"># may raise StopIteration</span></span><br><span class="line">        <span class="keyword">if</span> self._pin_memory:</span><br><span class="line">            data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)</span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;首先从 <code>_SingleProcessDataLoaderIter</code> 的初始化参数可以看到，其在父类 <code>_BaseDataLoaderIter</code> 的基础上定义了 <code>_dataset_fetcher</code>, 并传入 <code>_dataset</code>, <code>_auto_collation</code>, <code>_collate_fn</code> 等参数，该类用于根据指定的 Indices 来 Fetch 对应的 Samples，事实上就是我们前文提到过的 <b>Fetcher</b> 实体，我们在后面会对其源码进行分析。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;其次可以看见 <code>_SingleProcessDataLoaderIter</code> 实现了具体的 <code>_next_data()</code> 方法，其需要 <code>next_index()</code> 来获取要 Fetch 的 Samples 的 Indices，并将 Indices 传入 <code>_dataset_fetcher</code> 中以获取对应样本。

  <h4 class="title">多进程加载 Iterator: <code>_MultiProcessingDataLoaderIter</code> 类</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;当用户创建 <code>DataLoader</code> 时传入的 <code>num_workers</code> 大于 $1$ 的时候，对 <code>DataLoader</code> 的迭代操作就会基于 <code>_MultiProcessingDataLoaderIter</code> 类进行。我们将在 <ref>mp</ref> 中对其进行具体分析。

  <h3 class="title">单进程数据加载</h3>
  <div class="img" title="单进程数据加载调用链" label="img_single_process">
    <img src="./pic/single_process.png" width="90%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;现在我们来看用于单进程数据加载的基本流程，其基本调用关系如 <imgref>img_single_process</imgref> 所示。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;当我们在主程序的 <code>for</code> 循环中对 <code>DataLoader</code> 进行迭代时，其会 ① 首先调用 <code>DataLoader</code> 的 <code>__iter__(self)</code> 魔法方法以获得 Iterator，从上面展示过的程序中我们可以知道，在单进程数据加载的设定下，代表 Iterator 的类是  <code>_SingleProcessDataLoaderIter</code>；然后 ② 调用 <code>_SingleProcessDataLoaderIter</code> 的 <code>__next__</code> 以获取当前 Iteration 使用的 Sample Batch，从上一小节的分析我们知道:

  <ol>
    <li><code>_SingleProcessDataLoaderIter</code> 的 <code>__next__</code> 方法继承自父类 <code>_BaseDataLoaderIter</code>;</li>
    <li>父类 <code>_BaseDataLoaderIter</code> 的 <code>__next__</code> 方法实际上调用了 <code>_next_data</code> 方法来实现迭代逻辑，而后者留给子类实现;</li>
    <li>
      <code>_SingleProcessDataLoaderIter</code> 的 <code>_next_data</code> 方法过程可以分为三步:
      <div class="background">
      <ol>
        <li>调用 <code>_SingleProcessDataLoaderIter</code> 定义的 <code>next_index()</code> 从 <b>BatchSampler</b> (<b>Sampler</b>) 实体中获取 Sampled Indices (Index);</li>
        <li>基于 Sampled Indices (Index)，调用 <b>Fetcher</b> 实体从 <b>Dataset</b> 中获取并处理对应 Samples 的数据；</li>
        <li>将处理后的 Sample(s) 数据转移至 Pinned Memory (如果 <code>pin_memory==True</code>);</li>
      </ol>
      </div>
    </li>
  </ol>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;下面我们就 <code>_SingleProcessDataLoaderIter</code> 类定义的 <code>_next_data</code> 方法所实现的三步逻辑进行分析:

  <h4 class="paragraph">获取 Indices</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;上面看到的 <code>next_index()</code> 方法是在 <code>_SingleProcessDataLoaderIter</code> 的父类 <code>_BaseDataLoaderIter</code> 中定义的，我们把相关代码整理如下:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_BaseDataLoaderIter</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, loader: DataLoader</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        self._index_sampler = loader._index_sampler</span><br><span class="line">        self._sampler_iter = <span class="built_in">iter</span>(self._index_sampler)</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_next_index</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">next</span>(self._sampler_iter)  <span class="comment"># may raise StopIteration</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataLoader</span>(<span class="params">Generic[T_co]</span>):</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_auto_collation</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.batch_sampler <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_index_sampler</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self._auto_collation:</span><br><span class="line">            <span class="keyword">return</span> self.batch_sampler</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.sampler</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;从上面的代码可以看出，根据 <code>DataLoader</code> 中是否启用了了 <code>batch_sampler</code>，<code>next_index()</code> 将对应地从 <code>DataLoader</code> 的 <code>batch_sampler</code> 或者 <code>sampler</code> 中迭代出 Indices。

  <h4 class="paragraph">Samples 加载</h3>

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_DatasetKind</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">  Map = <span class="number">0</span></span><br><span class="line">  Iterable = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  @staticmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">create_fetcher</span>(<span class="params">kind, dataset, auto_collation, collate_fn, drop_last</span>):</span></span><br><span class="line">      <span class="keyword">if</span> kind == _DatasetKind.Map:</span><br><span class="line">          <span class="keyword">return</span> _utils.fetch._MapDatasetFetcher(dataset, auto_collation, collate_fn, drop_last)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          <span class="keyword">return</span> _utils.fetch._IterableDatasetFetcher(dataset, auto_collation, collate_fn, drop_last)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;现在来看 Samples 加载的部分，也即 <b>Fetcher</b> 实体。在 <code>_SingleProcessDataLoaderIter</code> 的构造函数中可以看到其调用了 <code>_DatasetKind.create_fetcher</code> 创建了 <b>Fetcher</b> 实体，相关代码如上所示。根据数据集类型的不同，该函数会创建出 <code>_MapDatasetFetcher</code> 类型或者 <code>_IterableDatasetFetcher</code> 类型的 <b>Fetcher</b> 实体，分别对应 Map-style 或者 Iterable-style 的数据集。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_MapDatasetFetcher</span>(<span class="params">_BaseDatasetFetcher</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dataset, auto_collation, collate_fn, drop_last</span>):</span></span><br><span class="line">      <span class="built_in">super</span>(_MapDatasetFetcher, self).__init__(dataset, auto_collation, collate_fn, drop_last)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">fetch</span>(<span class="params">self, possibly_batched_index</span>):</span></span><br><span class="line">      <span class="keyword">if</span> self.auto_collation:</span><br><span class="line">          data = [self.dataset[idx] <span class="keyword">for</span> idx <span class="keyword">in</span> possibly_batched_index]</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          data = self.dataset[possibly_batched_index]</span><br><span class="line">      <span class="keyword">return</span> self.collate_fn(data)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 <code>_MapDatasetFetcher</code> 类型 <b>Fetcher</b> 来说，如上所示，其定义的 <code>fetch()</code> 函数直接输入 Indices，作为 Map 的 Key，获得对应的样本，然后将获取的样本交给 <code>collate_fn</code> 指定的 Collate Function 进行输出前的整理。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_IterableDatasetFetcher</span>(<span class="params">_BaseDatasetFetcher</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dataset, auto_collation, collate_fn, drop_last</span>):</span></span><br><span class="line">      <span class="built_in">super</span>(_IterableDatasetFetcher, self).__init__(dataset, auto_collation, collate_fn, drop_last)</span><br><span class="line">      self.dataset_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line">      self.ended = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">fetch</span>(<span class="params">self, possibly_batched_index</span>):</span></span><br><span class="line">      <span class="keyword">if</span> self.ended:</span><br><span class="line">          <span class="keyword">raise</span> StopIteration</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> self.auto_collation:</span><br><span class="line">          data = []</span><br><span class="line">          <span class="keyword">for</span> _ <span class="keyword">in</span> possibly_batched_index:</span><br><span class="line">              <span class="keyword">try</span>:</span><br><span class="line">                  data.append(<span class="built_in">next</span>(self.dataset_iter))</span><br><span class="line">              <span class="keyword">except</span> StopIteration:</span><br><span class="line">                  self.ended = <span class="literal">True</span></span><br><span class="line">                  <span class="keyword">break</span></span><br><span class="line">          <span class="keyword">if</span> <span class="built_in">len</span>(data) == <span class="number">0</span> <span class="keyword">or</span> (self.drop_last <span class="keyword">and</span> <span class="built_in">len</span>(data) &lt; <span class="built_in">len</span>(possibly_batched_index)):</span><br><span class="line">              <span class="keyword">raise</span> StopIteration</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          data = <span class="built_in">next</span>(self.dataset_iter)</span><br><span class="line">      <span class="keyword">return</span> self.collate_fn(data)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 <code>_IterableDatasetFetcher</code> 类型 <b>Fetcher</b> 来说，如上所示，其在构造函数内设置了对应 Dataset 初始的迭代器，在 <code>fetch()</code> 方法内利用该迭代器获取元素，输入 <code>fetch()</code> 的 Indices 其实已经没有多大作用了。

  <h4 class="paragraph">转移至 Pinned Memory</h3>

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_SingleProcessDataLoaderIter</span>(<span class="params">_BaseDataLoaderIter</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, loader</span>):</span></span><br><span class="line">      <span class="built_in">super</span>(_SingleProcessDataLoaderIter, self).__init__(loader)</span><br><span class="line">      <span class="keyword">assert</span> self._timeout == <span class="number">0</span></span><br><span class="line">      <span class="keyword">assert</span> self._num_workers == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">      self._dataset_fetcher = _DatasetKind.create_fetcher(</span><br><span class="line">          self._dataset_kind, self._dataset, self._auto_collation, self._collate_fn, self._drop_last)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_next_data</span>(<span class="params">self</span>):</span></span><br><span class="line">      index = self._next_index()  <span class="comment"># may raise StopIteration</span></span><br><span class="line">      data = self._dataset_fetcher.fetch(index)  <span class="comment"># may raise StopIteration</span></span><br><span class="line">      <span class="keyword">if</span> self._pin_memory:</span><br><span class="line">          data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)</span><br><span class="line">      <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;从上面 <code>_SingleProcessDataLoaderIter</code> 的 <code>_next_data</code> 方法中可以看见，在 <b>Fetcher</b> 实体完成 Sample(s) 的加载和处理后，最后一步就是根据用户是否指定将 Tensor 数据转移至 Pinned Memory，调用 PyTorch 官方提供的 <code>_utils.pin_memory.pin_memory</code> 方法进行 Pinned Memory 的转移，这个函数我们在 <ref>pinned_memory</ref> 中进行了说明。

  <h3 class="title">多进程数据加载</h3>
  <label class="title">mp</label>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;我们下面首先对 PyTorch 多进程加载数据的逻辑进行概述，然后再结合具体代码分析 <code>_MultiProcessingDataLoaderIter</code> 的行为。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;如 <imgref>img_mp_dl</imgref> 所示，其展示了本文总结的多进程数据加载的流程。

  <div class="img" title="PyTorch 多进程数据加载逻辑" label="img_mp_dl">
    <img src="./pic/mp_fetching_logic.png" width="100%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在上图中，我们将多进程数据加载分为三个部分 —— <b>Initialization (初始化)</b>，<b>Fetching (读取处理)</b> 和 <b>Iteration (迭代)</b>。我们下面对着三个部分进行说明。

  <h4 class="title">Initialization</h4>
  <h5 class="paragraph">流程说明</h5>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;首先，当 <code>_MultiProcessingDataLoaderIter</code> 被创建时 (i.e. 其构造函数被运行时)，将会创建 <code>num_workers</code> 条 Worker 进程，一条用于将数据转移至 Pinned Memory 的线程，以及它们之间用于数据传输的若干异步队列。这些异步队列包括:

  <ul>
    <li><code>index_queue</code>: 每个 Worker 进程一条，主进程使用该队列用于通告 <b>BatchSampler</b> 输出的 Sampled Indices 给各个 Worker 进程;</li>
    <li><code>_worker_result_queue</code>: 全局唯一一条，用于存储各个 Worker 进程读取和处理好的 Mini-batches;</li>
    <li><code>_data_queue</code>: 全局唯一一条，用于 Pin Memory Thread 存储完成锁页内存转移的数据;</li>
  </ul>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;Initialization 部分除了创建多条 Worker 进程以外，如果 <code>DataLoader</code> 的 <code>pin_memory</code> 参数被使能的话，<code>_MultiProcessingDataLoaderIter</code> 的构造函数还会创建出一条 Python Thread —— Pinned Memory Thread，用于从 <code>_worker_result_queue</code> 中获取各条 Worker 进程读取并处理好的 Mini-batches，然后将数据转移到锁页内存中，最后再把数据放入 <code>_data_queue</code> 中。如果 <code>DataLoader</code> 的 <code>pin_memory</code> 参数没有被使能，则 <code>_worker_result_queue</code> 中的数据就将直接作为 <code>DataLoader</code> 的处理结果。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在完成 Worker 进程，Pin Memory 处理线程和异步队列的创建和初始化后，主进程将会向各个 Worker 进程发送它们分别的首次读取的 Indices，以启动它们的第一次数据读取。

  <h5 class="paragraph">相关代码</h5>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;上述流程的具体代码体现在 <code>_MultiProcessingDataLoaderIter</code> 的构造函数中，如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_MultiProcessingDataLoaderIter</span>(<span class="params">_BaseDataLoaderIter</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, loader</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(_MultiProcessingDataLoaderIter, self).__init__(loader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> self._num_workers &gt; <span class="number">0</span></span><br><span class="line">    <span class="keyword">assert</span> self._prefetch_factor &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 选择 Multiprocessing 模块的来源: </span></span><br><span class="line">    <span class="comment">#     [1] Python 官方 Multiprocessing 模块；或</span></span><br><span class="line">    <span class="comment">#     [2] PyTorch 提供的 Multiprocessing 模块；</span></span><br><span class="line">    <span class="keyword">if</span> loader.multiprocessing_context <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        multiprocessing_context = multiprocessing</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        multiprocessing_context = loader.multiprocessing_context</span><br><span class="line"></span><br><span class="line">    self._worker_init_fn = loader.worker_init_fn</span><br><span class="line">    <span class="comment"># No certainty which module multiprocessing_context is</span></span><br><span class="line">    self._worker_result_queue = multiprocessing_context.Queue()  <span class="comment"># type: ignore[var-annotated]</span></span><br><span class="line">    self._worker_pids_set = <span class="literal">False</span></span><br><span class="line">    self._shutdown = <span class="literal">False</span></span><br><span class="line">    self._workers_done_event = multiprocessing_context.Event()</span><br><span class="line"></span><br><span class="line">    self._index_queues = []</span><br><span class="line">    self._workers = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建 _num_workers 条 Worker 进程</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self._num_workers):</span><br><span class="line">        <span class="comment"># 创建 Per-worker 的 Index Queue</span></span><br><span class="line">        <span class="comment"># No certainty which module multiprocessing_context is</span></span><br><span class="line">        index_queue = multiprocessing_context.Queue()  <span class="comment"># type: ignore[var-annotated]</span></span><br><span class="line">        <span class="comment"># Need to `cancel_join_thread` here!</span></span><br><span class="line">        <span class="comment"># See sections (2) and (3b) above.</span></span><br><span class="line">        index_queue.cancel_join_thread()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建和启动 Worker 进程</span></span><br><span class="line">        w = multiprocessing_context.Process(</span><br><span class="line">            target=_utils.worker._worker_loop,</span><br><span class="line">            args=(self._dataset_kind, self._dataset, index_queue,</span><br><span class="line">                  self._worker_result_queue, self._workers_done_event,</span><br><span class="line">                  self._auto_collation, self._collate_fn, self._drop_last,</span><br><span class="line">                  self._base_seed, self._worker_init_fn, i, self._num_workers,</span><br><span class="line">                  self._persistent_workers, self._shared_seed))</span><br><span class="line">        w.daemon = <span class="literal">True</span></span><br><span class="line">        <span class="comment"># NB: Process.start() actually take some time as it needs to</span></span><br><span class="line">        <span class="comment">#     start a process and pass the arguments over via a pipe.</span></span><br><span class="line">        <span class="comment">#     Therefore, we only add a worker to self._workers list after</span></span><br><span class="line">        <span class="comment">#     it started, so that we do not call .join() if program dies</span></span><br><span class="line">        <span class="comment">#     before it starts, and __del__ tries to join but will get:</span></span><br><span class="line">        <span class="comment">#     AssertionError: can only join a started process.</span></span><br><span class="line">        w.start()</span><br><span class="line">        self._index_queues.append(index_queue)</span><br><span class="line">        self._workers.append(w)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果 DataLoader 使能了 _pin_memory</span></span><br><span class="line">    <span class="comment"># 则创建出一条 Python Thread 用于处理数据的锁页内存转移</span></span><br><span class="line">    <span class="comment"># 以及对应的异步队列 _data_queue</span></span><br><span class="line">    <span class="keyword">if</span> self._pin_memory:</span><br><span class="line">        self._pin_memory_thread_done_event = threading.Event()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Queue is not type-annotated</span></span><br><span class="line">        self._data_queue = queue.Queue()  <span class="comment"># type: ignore[var-annotated]</span></span><br><span class="line">        pin_memory_thread = threading.Thread(</span><br><span class="line">            target=_utils.pin_memory._pin_memory_loop,</span><br><span class="line">            args=(self._worker_result_queue, self._data_queue,</span><br><span class="line">                  torch.cuda.current_device(),</span><br><span class="line">                  self._pin_memory_thread_done_event, self._pin_memory_device))</span><br><span class="line">        pin_memory_thread.daemon = <span class="literal">True</span></span><br><span class="line">        pin_memory_thread.start()</span><br><span class="line">        <span class="comment"># Similar to workers (see comment above), we only register</span></span><br><span class="line">        <span class="comment"># pin_memory_thread once it is started.</span></span><br><span class="line">        self._pin_memory_thread = pin_memory_thread</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self._data_queue = self._worker_result_queue</span><br><span class="line"></span><br><span class="line">    <span class="comment"># In some rare cases, persistent workers (daemonic processes)</span></span><br><span class="line">    <span class="comment"># would be terminated before `__del__` of iterator is invoked</span></span><br><span class="line">    <span class="comment"># when main process exits</span></span><br><span class="line">    <span class="comment"># It would cause failure when pin_memory_thread tries to read</span></span><br><span class="line">    <span class="comment"># corrupted data from worker_result_queue</span></span><br><span class="line">    <span class="comment"># atexit is used to shutdown thread and child processes in the</span></span><br><span class="line">    <span class="comment"># right sequence before main process exits</span></span><br><span class="line">    <span class="keyword">if</span> self._persistent_workers <span class="keyword">and</span> self._pin_memory:</span><br><span class="line">        <span class="keyword">import</span> atexit</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> self._workers:</span><br><span class="line">            atexit.register(_MultiProcessingDataLoaderIter._clean_up_worker, w)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># .pid can be None only before process is spawned (not the case, so ignore)</span></span><br><span class="line">    _utils.signal_handling._set_worker_pids(<span class="built_in">id</span>(self), <span class="built_in">tuple</span>(w.pid <span class="keyword">for</span> w <span class="keyword">in</span> self._workers))  <span class="comment"># type: ignore[misc]</span></span><br><span class="line">    _utils.signal_handling._set_SIGCHLD_handler()</span><br><span class="line">    self._worker_pids_set = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 重置 _MultiProcessingDataLoaderIter</span></span><br><span class="line">    <span class="comment"># 在这里第一次被调用，实际上是初始化</span></span><br><span class="line">    self._reset(loader, first_iter=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;上面代码的最后一行调用的 <code>_reset</code> 函数如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_MultiProcessingDataLoaderIter</span>(<span class="params">_BaseDataLoaderIter</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_reset</span>(<span class="params">self, loader, first_iter=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>()._reset(loader, first_iter)</span><br><span class="line">        self._send_idx = <span class="number">0</span>  <span class="comment"># idx of the next task to be sent to workers</span></span><br><span class="line">        self._rcvd_idx = <span class="number">0</span>  <span class="comment"># idx of the next task to be returned in __next__</span></span><br><span class="line">        <span class="comment"># information about data not yet yielded, i.e., tasks w/ indices in range [rcvd_idx, send_idx).</span></span><br><span class="line">        <span class="comment"># map: task idx =&gt; - (worker_id,)        if data isn&#x27;t fetched (outstanding)</span></span><br><span class="line">        <span class="comment">#                  \ (worker_id, data)   if data is already fetched (out-of-order)</span></span><br><span class="line">        self._task_info = &#123;&#125;</span><br><span class="line">        self._tasks_outstanding = <span class="number">0</span>  <span class="comment"># always equal to count(v for v in task_info.values() if len(v) == 1)</span></span><br><span class="line">        <span class="comment"># A list of booleans representing whether each worker still has work to</span></span><br><span class="line">        <span class="comment"># do, i.e., not having exhausted its iterable dataset object. It always</span></span><br><span class="line">        <span class="comment"># contains all `True`s if not using an iterable-style dataset</span></span><br><span class="line">        <span class="comment"># (i.e., if kind != Iterable).</span></span><br><span class="line">        <span class="comment"># Not that this indicates that a worker still has work to do *for this epoch*.</span></span><br><span class="line">        <span class="comment"># It does not mean that a worker is dead. In case of `_persistent_workers`,</span></span><br><span class="line">        <span class="comment"># the worker will be reset to available in the next epoch.</span></span><br><span class="line">        self._workers_status = [<span class="literal">True</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self._num_workers)]</span><br><span class="line">        <span class="comment"># Reset the worker queue cycle so it resumes next epoch at worker 0</span></span><br><span class="line">        self._worker_queue_idx_cycle = itertools.cycle(<span class="built_in">range</span>(self._num_workers))</span><br><span class="line">        <span class="comment"># We resume the prefetching in case it was enabled</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> first_iter:</span><br><span class="line">            <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(self._num_workers):</span><br><span class="line">                self._index_queues[idx].put(_utils.worker._ResumeIteration(self._shared_seed))</span><br><span class="line">            resume_iteration_cnt = self._num_workers</span><br><span class="line">            <span class="keyword">while</span> resume_iteration_cnt &gt; <span class="number">0</span>:</span><br><span class="line">                return_idx, return_data = self._get_data()</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(return_idx, _utils.worker._ResumeIteration):</span><br><span class="line">                    <span class="keyword">assert</span> return_data <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line">                    resume_iteration_cnt -= <span class="number">1</span></span><br><span class="line">        <span class="comment"># prime the prefetch loop</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self._prefetch_factor * self._num_workers):</span><br><span class="line">            self._try_put_index()</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在上面代码的最后两行，<code>_reset</code> 函数通过一个 <code>for</code> 循环，向各条 Worker 进程的 <code>index_queue</code> 中放入了 Batch Indices，放入的次数是 <code>_prefetch_factor</code> $\times$ <code>_num_workers</code>，也即当 <code>_prefetch_factor</code> $= 1$ 时，每个 Worker 进程就只会收到 $1$ 个 Batch Indices，<code>_prefetch_factor</code> $= 2$ 时则收到 $2$ 个。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;上面代码最后一行所调用的 <code>_try_put_index</code> 函数定义如下所示，其用于向下一个 Active 的 Worker 进程的 <code>_index_queues</code> 中放入 $1$ 个 Batch Indices。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_MultiProcessingDataLoaderIter</span>(<span class="params">_BaseDataLoaderIter</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_try_put_index</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> self._tasks_outstanding &lt; self._prefetch_factor * self._num_workers</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            index = self._next_index()</span><br><span class="line">        <span class="keyword">except</span> StopIteration:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self._num_workers):  <span class="comment"># find the next active worker, if any</span></span><br><span class="line">            worker_queue_idx = <span class="built_in">next</span>(self._worker_queue_idx_cycle)</span><br><span class="line">            <span class="keyword">if</span> self._workers_status[worker_queue_idx]:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># not found (i.e., didn&#x27;t break)</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        self._index_queues[worker_queue_idx].put((self._send_idx, index))</span><br><span class="line">        self._task_info[self._send_idx] = (worker_queue_idx,)</span><br><span class="line">        self._tasks_outstanding += <span class="number">1</span></span><br><span class="line">        self._send_idx += <span class="number">1</span></span><br></pre></td></tr></table></figure>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在上面的代码中，我们可以看到:

  <ul>
    <li>
    调用了 <code>_next_index</code> 函数用于获取下一个 Batch Indices，该函数实际上就是对 Sampler 的一次迭代:
    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_MultiProcessingDataLoaderIter</span>(<span class="params">_BaseDataLoaderIter</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_next_index</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">next</span>(self._sampler_iter)  <span class="comment"># may raise StopIteration</span></span><br></pre></td></tr></table></figure>
    </li>
    <li><code>_MultiProcessingDataLoaderIter</code> 使用 <code>_task_info</code> 字典用于记录每一个 Batch Indices 被处理的具体信息，字典的键是处理这个 Batch Indices 的 Worker 的 Index，字典的值是 Worker 进程读取和处理完成后的数据;</li>
    <li><code>_MultiProcessingDataLoaderIter</code> 使用 <code>_tasks_outstanding</code> 变量用于记录 <def>尚未被交付的 (Outstanding)</def> 任务的个数;</code></li>
    <li><code>_MultiProcessingDataLoaderIter</code> 使用 <code>_send_idx</code> 变量用于记录当前已经完成部署的 Batch Indices 的批次号;</li>
  </ul>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在完成 <code>_reset</code> 函数的运行后，<code>_MultiProcessingDataLoaderIter</code> 就完成了 Initialization 部分的工作。

  <h4 class="title">Fetching</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;现在我们来关心在每个 Worker 进程内部发生的事情。Worker 进程实际上就是负责根据主进程的 <b>Sampler</b> 输出的 Indices，在 <b>Dataset</b> 中完成数据的提取和处理，其核心工作流程可以类比单进程数据加载的流程。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在主进程初始化 Worker 进程的代码中，我们注意到 Worker 进程的运行函数是 <code>_utils.worker._worker_loop</code> 函数，在该函数中最关键的程序是其处理循环，我们将这段代码摘抄如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_worker_loop</span>(<span class="params">...</span>):</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># ...</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 运行 _worker_init_fn，以及创建 fetcher</span></span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">      <span class="keyword">if</span> init_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">          init_fn(worker_id)</span><br><span class="line"></span><br><span class="line">      fetcher = _DatasetKind.create_fetcher(dataset_kind, dataset, auto_collation, collate_fn, drop_last)</span><br><span class="line">  <span class="keyword">except</span> Exception:</span><br><span class="line">      init_exception = ExceptionWrapper(</span><br><span class="line">          where=<span class="string">&quot;in DataLoader worker process &#123;&#125;&quot;</span>.<span class="built_in">format</span>(worker_id))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># When using Iterable mode, some worker can exit earlier than others due</span></span><br><span class="line">  <span class="comment"># to the IterableDataset behaving differently for different workers.</span></span><br><span class="line">  <span class="comment"># When such things happen, an `_IterableDatasetStopIteration` object is</span></span><br><span class="line">  <span class="comment"># sent over to the main process with the ID of this worker, so that the</span></span><br><span class="line">  <span class="comment"># main process won&#x27;t send more tasks to this worker, and will send</span></span><br><span class="line">  <span class="comment"># `None` to this worker to properly exit it.</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># Note that we cannot set `done_event` from a worker as it is shared</span></span><br><span class="line">  <span class="comment"># among all processes. Instead, we set the `iteration_end` flag to</span></span><br><span class="line">  <span class="comment"># signify that the iterator is exhausted. When either `done_event` or</span></span><br><span class="line">  <span class="comment"># `iteration_end` is set, we skip all processing step and just wait for</span></span><br><span class="line">  <span class="comment"># `None`.</span></span><br><span class="line">  iteration_end = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  watchdog = ManagerWatchdog()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> watchdog.is_alive():</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 从 index_queue 中接收来自主进程的消息</span></span><br><span class="line">        r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)</span><br><span class="line">    <span class="keyword">except</span> queue.Empty:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 收到 _ResumeIteration —— 重新开始迭代的消息</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(r, _ResumeIteration):</span><br><span class="line">        <span class="comment"># Acknowledge the main process</span></span><br><span class="line">        data_queue.put((r, <span class="literal">None</span>))</span><br><span class="line">        iteration_end = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(dataset, IterDataPipe):</span><br><span class="line">            <span class="keyword">assert</span> r.seed <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">            shared_rng.manual_seed(r.seed)</span><br><span class="line">            dataset = apply_shuffle_seed(dataset, shared_rng)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Recreate the fetcher for worker-reuse policy</span></span><br><span class="line">        fetcher = _DatasetKind.create_fetcher(</span><br><span class="line">            dataset_kind, dataset, auto_collation, collate_fn, drop_last)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 收到 None —— 通知结束当前 Worker 进程的消息</span></span><br><span class="line">    <span class="keyword">elif</span> r <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># Received the final signal</span></span><br><span class="line">        <span class="keyword">assert</span> done_event.is_set() <span class="keyword">or</span> iteration_end</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果 Done Event 已经被置位，或者迭代已经结束，则不执行后续的读取操作</span></span><br><span class="line">    <span class="comment"># 转而不断重复上面的流程，直到收到 None</span></span><br><span class="line">    <span class="keyword">elif</span> done_event.is_set() <span class="keyword">or</span> iteration_end:</span><br><span class="line">        <span class="comment"># `done_event` is set. But I haven&#x27;t received the final signal</span></span><br><span class="line">        <span class="comment"># (None) yet. I will keep continuing until get it, and skip the</span></span><br><span class="line">        <span class="comment"># processing steps.</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析收到的消息</span></span><br><span class="line">    idx, index = r</span><br><span class="line">    data: Union[_IterableDatasetStopIteration, ExceptionWrapper]</span><br><span class="line">    <span class="keyword">if</span> init_exception <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        data = init_exception</span><br><span class="line">        init_exception = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 从 Dataset 中提取数据</span></span><br><span class="line">            data = fetcher.fetch(index)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="comment"># 迭代 Iterable Dataset 时遇到 StopIteration 异常，代表迭代结束</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(e, StopIteration) <span class="keyword">and</span> dataset_kind == _DatasetKind.Iterable:</span><br><span class="line">                data = _IterableDatasetStopIteration(worker_id)</span><br><span class="line">                <span class="comment"># Set `iteration_end`</span></span><br><span class="line">                <span class="comment">#   (1) to save future `next(...)` calls, and</span></span><br><span class="line">                <span class="comment">#   (2) to avoid sending multiple `_IterableDatasetStopIteration`s.</span></span><br><span class="line">                iteration_end = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># It is important that we don&#x27;t store exc_info in a variable.</span></span><br><span class="line">                <span class="comment"># `ExceptionWrapper` does the correct thing.</span></span><br><span class="line">                <span class="comment"># See NOTE [ Python Traceback Reference Cycle Problem ]</span></span><br><span class="line">                data = ExceptionWrapper(</span><br><span class="line">                    where=<span class="string">&quot;in DataLoader worker process &#123;&#125;&quot;</span>.<span class="built_in">format</span>(worker_id))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将提取并整理好的数据放入 data_queue 中</span></span><br><span class="line">    data_queue.put((idx, data))</span><br><span class="line">    <span class="keyword">del</span> data, idx, index, r  <span class="comment"># save memory</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;可以看到，Worker 进程将从 <code>index_queue</code> 中接收指示其进行对应操作的消息 (Line 34)，正常来说将从主进程接收到 <code>idx, index</code> 格式的消息，其中 <code>idx</code> 代表了主进程让当前 Worker 进程取出的 Mini-batch 的编号，<code>index</code> 则包含了具体的 Samples 的索引，在利用 <code>Fetcher</code> 实体完成数据的提取和整理后 (Line 77)，Worker 进程会把数据放入 <code>_worker_result_queue</code> 中 (Line 94)。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 Iterable-style Dataset，Worker 进程设置了 <code>iteration_end</code> 指示变量来标识迭代的结束: 当从 <code>Fetcher</code> 实体中得到 <code>StopIteration</code> 异常时 (Line 80)，将会置位 <code>iteration_end</code>，并且 Worker 进程会通过 <code>_worker_result_queue</code> 将迭代结束的消息通告给主进程 (Line 81)。当 <code>iteration_end</code> 被置位时，后续的处理循环将不会再进行任何的数据获取和处理操作 (Line 62)。当 Worker 进程从 <code>index_queue</code> 中接收到 <code>None</code> 消息时，说明主进程通告当前 Worker 进程结束，Worker 进程跳出处理循环，进程结束 (Line 55)。

  <h4 class="title">Iteration</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;下面我们来看 <code>_MultiProcessingDataLoaderIter</code> 的 <code>_next_data</code> 方法:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_MultiProcessingDataLoaderIter</span>(<span class="params">_BaseDataLoaderIter</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">...</span>):</span></span><br><span class="line">      <span class="comment">#...</span></span><br><span class="line">      self._reset(loader, first_iter=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_reset</span>(<span class="params">self, loader, first_iter=<span class="literal">False</span></span>):</span></span><br><span class="line">      self._send_idx = <span class="number">0</span>  <span class="comment"># idx of the next task to be sent to workers</span></span><br><span class="line">      self._rcvd_idx = <span class="number">0</span>  <span class="comment"># idx of the next task to be returned in __next__</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># ...</span></span><br><span class="line">    </span><br><span class="line">      <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self._prefetch_factor * self._num_workers):</span><br><span class="line">          self._try_put_index()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_try_put_index</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="comment"># ...</span></span><br><span class="line">      self._send_idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_next_data</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="comment"># If the worker responsible for `self._rcvd_idx` has already ended</span></span><br><span class="line">            <span class="comment"># and was unable to fulfill this task (due to exhausting an `IterableDataset`),</span></span><br><span class="line">            <span class="comment"># we try to advance `self._rcvd_idx` to find the next valid index.</span></span><br><span class="line">            <span class="comment">#</span></span><br><span class="line">            <span class="comment"># This part needs to run in the loop because both the `self._get_data()`</span></span><br><span class="line">            <span class="comment"># call and `_IterableDatasetStopIteration` check below can mark</span></span><br><span class="line">            <span class="comment"># extra worker(s) as dead.</span></span><br><span class="line">            <span class="keyword">while</span> self._rcvd_idx &lt; self._send_idx:</span><br><span class="line">                info = self._task_info[self._rcvd_idx]</span><br><span class="line">                worker_id = info[<span class="number">0</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(info) == <span class="number">2</span> <span class="keyword">or</span> self._workers_status[worker_id]:  <span class="comment"># has data or is still active</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">del</span> self._task_info[self._rcvd_idx]</span><br><span class="line">                self._rcvd_idx += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># no valid `self._rcvd_idx` is found (i.e., didn&#x27;t break)</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> self._persistent_workers:</span><br><span class="line">                    self._shutdown_workers()</span><br><span class="line">                <span class="keyword">raise</span> StopIteration</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Now `self._rcvd_idx` is the batch index we want to fetch</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Check if the next sample has already been generated</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(self._task_info[self._rcvd_idx]) == <span class="number">2</span>:</span><br><span class="line">                data = self._task_info.pop(self._rcvd_idx)[<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">return</span> self._process_data(data)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">assert</span> <span class="keyword">not</span> self._shutdown <span class="keyword">and</span> self._tasks_outstanding &gt; <span class="number">0</span></span><br><span class="line">            idx, data = self._get_data()</span><br><span class="line">            self._tasks_outstanding -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> self._dataset_kind == _DatasetKind.Iterable:</span><br><span class="line">                <span class="comment"># Check for _IterableDatasetStopIteration</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(data, _utils.worker._IterableDatasetStopIteration):</span><br><span class="line">                    <span class="keyword">if</span> self._persistent_workers:</span><br><span class="line">                        self._workers_status[data.worker_id] = <span class="literal">False</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        self._mark_worker_as_unavailable(data.worker_id)</span><br><span class="line">                    self._try_put_index()</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> idx != self._rcvd_idx:</span><br><span class="line">                <span class="comment"># store out-of-order samples</span></span><br><span class="line">                self._task_info[idx] += (data,)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">del</span> self._task_info[idx]</span><br><span class="line">                <span class="keyword">return</span> self._process_data(data)</span><br></pre></td></tr></table></figure>
</div>


<div class="div_ref" id="ref_container"></div>

</body>

<!-- 圆圈数字 -->
<!--
⓪ ① ② ③ ④ ⑤ ⑥ ⑦ ⑧ ⑨ ⑩ ⑪ ⑫ ⑬ ⑭ ⑮ ⑯ ⑰ ⑱ ⑲ ⑳ ㉑ ㉒ ㉓ ㉔ ㉕ ㉖ ㉗ ㉘ ㉙ ㉚ ㉛ ㉜ ㉝ ㉞ ㉟ ㊱ ㊲ ㊳ ㊴ ㊵ ㊶ ㊷ ㊸ ㊹ ㊺ ㊻ ㊼ ㊽ ㊾ ㊿
-->

<!-- Flow Chart -->
<!--
Format see: https://mermaid-js.github.io/mermaid/#/flowchart
-->
<!-- <flowchart class="mermaid">
 Mermaid Flow Chart Code
</flowchart> -->

<!-- Sign Block -->
<!--
<noteblock>
A NOTE
</noteblock>

<queblock>
A QUESTION
</queblock>
-->

<!--图片、引用-->
<!-- 
<div class="img" title="img title" label="img_label" source="url">
  <img src="" height="" />
</div>

<imaging>img_label</imaging>
-->

<!--等式、引用-->
<!-- 
<div class="equation" label="equation_label">
</div>

<equation>equation_label</equation>
-->

<!--定理、引用、证明-->
<!-- 
<div class="theorm" label="theorm_label">
</div>

<theorm>theorm_label</theorm>

<div class="theorm_prove">
</div>
-->

<!--引用其它章节-->
<!-- 
<ref></ref> 
-->

<!--引用文献-->
<!-- 
<cite></cite> 
-->

<!--关键词-->
<!-- 
<def></def> 
-->

<!--醒目注意-->
<!-- 
<note></note> 
-->

<!--段落-->
<!--
<h3 class="paragraph">Paragraph Name</h3>
-->

<!--表格-->
<!--
<div class="table" title="Table Title" label="table_label">
  <table border="1" align="center" bgcolor="#FFFFFF">
    <tr>
      <th>A</th>
      <th>B</th>
      <th>C</th>
    </tr>
    <tr>
      <td>xxx</td>
      <td>xxx</td>
      <td>xxx</td>
    </tr>
  </table>
</div>
-->

<!--矩阵公式-->
<!--
<div class="cmath" align="center">
  `((1, 0),(1, 0))`
</div><br>
-->

<!--伪代码-->
<!--
<pre id="quicksort" style="display:hidden;">
  % This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
  \begin{algorithm}
  \caption{Quicksort}
  \begin{algorithmic}
  \PROCEDURE{Quicksort}{$A, p, r$}
      % Add Here

      % 空行
      % \STATE \texttt{\\}
  \ENDPROCEDURE
  \end{algorithmic}
  \end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("quicksort"));
</script>
-->
<!--
Latex 伪代码格式见: https://github.com/SaswatPadhi/pseudocode.js
-->

<!--图片-->
<!--
<div align="center">
  <img src="./pic/xxx.png" width=80%>
</div>
-->

<!--正文-->
<!--
<p>
&nbsp;&nbsp;&nbsp;&nbsp;公式：<span>`\overline{A}\overline{B}`</span>
</p>
-->
      </div>
      
      
      
    </div>
    
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Tech_System_And_Network/">TECH_SYSTEM_AND_NETWORK</a></li>
          <li>PYTORCH_DATALOADER</li>
        
  </ul>

    
    
    


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhuobin Huang"
      src="/images/avatar_2.png">
  <p class="site-author-name" itemprop="name">Zhuobin Huang</p>
  <div class="site-description" itemprop="description">System Engineer</div>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhuobin Huang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
